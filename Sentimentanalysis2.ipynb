{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "760b683c-6413-40c5-beb5-623af5ec5f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025-05-12 21:53:36.421 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-05-12 21:53:36.427 Session state does not function when running a script without `streamlit run`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "         Acceptance          0.00      0.00      0.00         2\n",
      "      Acceptance             0.00      0.00      0.00         0\n",
      "           Admiration        0.00      0.00      0.00         1\n",
      "        Admiration           0.00      0.00      0.00         1\n",
      "         Affection           0.00      0.00      0.00         1\n",
      "      Ambivalence            0.00      0.00      0.00         1\n",
      "         Anger               0.00      0.00      0.00         1\n",
      "        Anticipation         0.00      0.00      0.00         1\n",
      "        Arousal              0.00      0.00      0.00         3\n",
      "                  Awe        0.00      0.00      0.00         1\n",
      "         Awe                 0.00      0.00      0.00         1\n",
      "                  Bad        0.00      0.00      0.00         1\n",
      "             Betrayal        0.00      0.00      0.00         2\n",
      "        Betrayal             0.00      0.00      0.00         1\n",
      "         Bitter              0.00      0.00      0.00         1\n",
      "           Bitterness        0.00      0.00      0.00         1\n",
      "          Bittersweet        0.00      0.00      0.00         1\n",
      "              Boredom        0.00      0.00      0.00         1\n",
      "         Calmness            0.00      0.00      0.00         1\n",
      "          Captivation        0.00      0.00      0.00         1\n",
      "     Celestial Wonder        0.00      0.00      0.00         1\n",
      "             Colorful        0.00      0.00      0.00         1\n",
      "      Confusion              0.00      0.00      0.00         3\n",
      "           Connection        0.00      0.00      0.00         1\n",
      "        Contemplation        0.00      0.00      0.00         1\n",
      "          Contentment        0.00      0.00      0.00         3\n",
      "        Contentment          0.00      0.00      0.00         1\n",
      "         Coziness            0.00      0.00      0.00         1\n",
      "         Creativity          0.00      0.00      0.00         1\n",
      "            Curiosity        0.00      0.00      0.00         2\n",
      "          Curiosity          0.00      0.00      0.00         1\n",
      "      Curiosity              0.00      0.00      0.00         2\n",
      "           Desolation        0.00      0.00      0.00         1\n",
      "           Devastated        0.00      0.00      0.00         2\n",
      "              Disgust        0.00      0.00      0.00         1\n",
      "         Disgust             0.00      0.00      0.00         2\n",
      "        Elation              0.00      0.00      0.00         3\n",
      "             Elegance        0.00      0.00      0.00         1\n",
      "          Embarrassed        0.00      0.00      0.00         1\n",
      "       EmotionalStorm        0.00      0.00      0.00         1\n",
      "        Empowerment          0.00      0.00      0.00         1\n",
      "         Enjoyment           0.00      0.00      0.00         2\n",
      "           Enthusiasm        0.00      0.00      0.00         1\n",
      "              Envious        0.00      0.00      0.00         2\n",
      "  Envisioning History        0.00      0.00      0.00         1\n",
      "         Euphoria            0.00      0.00      0.00         1\n",
      "           Excitement        0.05      0.33      0.08         3\n",
      "         Excitement          0.00      0.00      0.00         3\n",
      "        Excitement           0.00      0.00      0.00         1\n",
      "         Fear                0.00      0.00      0.00         1\n",
      "              Fearful        0.00      0.00      0.00         1\n",
      "           Frustrated        0.00      0.00      0.00         1\n",
      "          Frustration        0.00      0.00      0.00         3\n",
      "         Fulfillment         0.00      0.00      0.00         2\n",
      "             Grateful        0.00      0.00      0.00         1\n",
      "      Grief                  0.00      0.00      0.00         1\n",
      "                Happy        0.00      0.00      0.00         6\n",
      "                 Hate        0.00      0.00      0.00         2\n",
      "           Heartbreak        0.00      0.00      0.00         2\n",
      "              Hopeful        1.00      1.00      1.00         1\n",
      "        InnerJourney         0.00      0.00      0.00         1\n",
      "        Inspiration          0.00      0.00      0.00         1\n",
      "             Inspired        0.00      0.00      0.00         1\n",
      "            Isolation        0.00      0.00      0.00         1\n",
      "          Jealousy           0.00      0.00      0.00         1\n",
      "                  Joy        0.12      1.00      0.22         8\n",
      "         Joy                 0.00      0.00      0.00         1\n",
      "        JoyfulReunion        0.00      0.00      0.00         1\n",
      "         Kind                0.00      0.00      0.00         1\n",
      "           Loneliness        0.00      0.00      0.00         1\n",
      "      Loneliness             0.00      0.00      0.00         1\n",
      "             LostLove        0.00      0.00      0.00         1\n",
      "      Melancholy             0.00      0.00      0.00         2\n",
      "       Miscalculation        0.00      0.00      0.00         1\n",
      "              Neutral        0.00      0.00      0.00         1\n",
      "        Nostalgia            0.00      0.00      0.00         1\n",
      "      Nostalgia              0.00      0.00      0.00         1\n",
      "      Numbness               0.00      0.00      0.00         1\n",
      "          Overwhelmed        0.00      0.00      0.00         1\n",
      "              Playful        0.00      0.00      0.00         2\n",
      "            Positive         0.14      0.89      0.24         9\n",
      "                Proud        0.00      0.00      0.00         1\n",
      "        Reflection           0.00      0.00      0.00         1\n",
      "       Regret                0.00      0.00      0.00         1\n",
      "           Resilience        0.00      0.00      0.00         1\n",
      "            Reverence        0.00      0.00      0.00         1\n",
      "         Sadness             0.00      0.00      0.00         2\n",
      "        Satisfaction         0.00      0.00      0.00         1\n",
      "             Serenity        0.00      0.00      0.00         2\n",
      "      Serenity               0.00      0.00      0.00         2\n",
      "             Solitude        0.00      0.00      0.00         1\n",
      "          Sorrow             0.00      0.00      0.00         1\n",
      "         Spark               0.00      0.00      0.00         1\n",
      "         Surprise            0.00      0.00      0.00         1\n",
      "        Thrill               0.00      0.00      0.00         1\n",
      "             Vibrancy        0.00      0.00      0.00         1\n",
      " Whispers of the Past        0.00      0.00      0.00         1\n",
      "                 Zest        0.00      0.00      0.00         1\n",
      "\n",
      "              accuracy                           0.12       147\n",
      "             macro avg       0.01      0.03      0.02       147\n",
      "          weighted avg       0.02      0.12      0.03       147\n",
      "\n",
      "Confusion Matrix:\n",
      " [[0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# sentiment_analysis.py\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import streamlit as st\n",
    "\n",
    "# 1. Load Dataset\n",
    "df = pd.read_csv(\"sentimentdataset.csv\")  # Make sure your CSV has 'text' and 'emotion' columns\n",
    "\n",
    "# 2. Preprocessing Function\n",
    "def clean_text(Text):\n",
    "    text = re.sub(r\"http\\\\S+\", \"\", Text)\n",
    "    text = re.sub(r\"@[A-Za-z0-9_]+\", \"\", Text)\n",
    "    text = re.sub(r\"#[A-Za-z0-9_]+\", \"\", Text)\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text\n",
    "\n",
    "df[\"clean_text\"] = df[\"Text\"].apply(clean_text)\n",
    "\n",
    "# 3. Vectorization\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(df[\"clean_text\"])\n",
    "y = df[\"Sentiment\"]\n",
    "\n",
    "# 4. Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 5. Train Logistic Regression Model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 6. Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 7. Streamlit Web App\n",
    "st.title(\"🧠 Emotion Detector from Social Media Text\")\n",
    "user_input = st.text_area(\"Enter a tweet or comment:\")\n",
    "\n",
    "if st.button(\"Analyze Emotion\"):\n",
    "    cleaned = clean_text(user_input)\n",
    "    vectorized = tfidf.transform([cleaned])\n",
    "    prediction = model.predict(vectorized)[0]\n",
    "    st.success(f\"Predicted Emotion: **{prediction}**\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6de440e7-f6dd-4dcf-b944-193a1c73105b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 732\n",
      "Number of columns: 15\n",
      "\n",
      "Column Names: ['Unnamed: 0.1', 'Unnamed: 0', 'Text', 'Sentiment', 'Timestamp', 'User', 'Platform', 'Hashtags', 'Retweets', 'Likes', 'Country', 'Year', 'Month', 'Day', 'Hour']\n",
      "\n",
      "First 5 records:\n",
      "   Unnamed: 0.1  Unnamed: 0  \\\n",
      "0             0           0   \n",
      "1             1           1   \n",
      "2             2           2   \n",
      "3             3           3   \n",
      "4             4           4   \n",
      "\n",
      "                                                Text    Sentiment  \\\n",
      "0   Enjoying a beautiful day at the park!        ...   Positive     \n",
      "1   Traffic was terrible this morning.           ...   Negative     \n",
      "2   Just finished an amazing workout! 💪          ...   Positive     \n",
      "3   Excited about the upcoming weekend getaway!  ...   Positive     \n",
      "4   Trying out a new recipe for dinner tonight.  ...   Neutral      \n",
      "\n",
      "             Timestamp            User     Platform  \\\n",
      "0  2023-01-15 12:30:00   User123          Twitter     \n",
      "1  2023-01-15 08:45:00   CommuterX        Twitter     \n",
      "2  2023-01-15 15:45:00   FitnessFan      Instagram    \n",
      "3  2023-01-15 18:20:00   AdventureX       Facebook    \n",
      "4  2023-01-15 19:55:00   ChefCook        Instagram    \n",
      "\n",
      "                                     Hashtags  Retweets  Likes       Country  \\\n",
      "0   #Nature #Park                                  15.0   30.0     USA         \n",
      "1   #Traffic #Morning                               5.0   10.0     Canada      \n",
      "2   #Fitness #Workout                              20.0   40.0   USA           \n",
      "3   #Travel #Adventure                              8.0   15.0     UK          \n",
      "4   #Cooking #Food                                 12.0   25.0    Australia    \n",
      "\n",
      "   Year  Month  Day  Hour  \n",
      "0  2023      1   15    12  \n",
      "1  2023      1   15     8  \n",
      "2  2023      1   15    15  \n",
      "3  2023      1   15    18  \n",
      "4  2023      1   15    19  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"sentimentdataset.csv\")\n",
    "\n",
    "# Get the size and structure\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "print(\"\\nColumn Names:\", df.columns.tolist())\n",
    "\n",
    "# Preview the first 5 rows\n",
    "print(\"\\nFirst 5 records:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f728fe7-bcd1-4c33-ab40-8aeaf0cf4f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before:\n",
      " Unnamed: 0.1    0\n",
      "Unnamed: 0      0\n",
      "Text            0\n",
      "Sentiment       0\n",
      "Timestamp       0\n",
      "User            0\n",
      "Platform        0\n",
      "Hashtags        0\n",
      "Retweets        0\n",
      "Likes           0\n",
      "Country         0\n",
      "Year            0\n",
      "Month           0\n",
      "Day             0\n",
      "Hour            0\n",
      "dtype: int64\n",
      "Missing values after:\n",
      " Unnamed: 0.1    0\n",
      "Unnamed: 0      0\n",
      "Text            0\n",
      "Sentiment       0\n",
      "Timestamp       0\n",
      "User            0\n",
      "Platform        0\n",
      "Hashtags        0\n",
      "Retweets        0\n",
      "Likes           0\n",
      "Country         0\n",
      "Year            0\n",
      "Month           0\n",
      "Day             0\n",
      "Hour            0\n",
      "dtype: int64\n",
      "Removed 0 duplicate rows.\n",
      "Numerical features scaled.\n",
      "   Unnamed: 0.1  Unnamed: 0  \\\n",
      "0     -1.733763   -1.741727   \n",
      "1     -1.729032   -1.737017   \n",
      "2     -1.724301   -1.732306   \n",
      "3     -1.719570   -1.727595   \n",
      "4     -1.714839   -1.722884   \n",
      "\n",
      "                                                Text    Sentiment  \\\n",
      "0   Enjoying a beautiful day at the park!        ...   Positive     \n",
      "1   Traffic was terrible this morning.           ...   Negative     \n",
      "2   Just finished an amazing workout! 💪          ...   Positive     \n",
      "3   Excited about the upcoming weekend getaway!  ...   Positive     \n",
      "4   Trying out a new recipe for dinner tonight.  ...   Neutral      \n",
      "\n",
      "             Timestamp            User     Platform  \\\n",
      "0  2023-01-15 12:30:00   User123          Twitter     \n",
      "1  2023-01-15 08:45:00   CommuterX        Twitter     \n",
      "2  2023-01-15 15:45:00   FitnessFan      Instagram    \n",
      "3  2023-01-15 18:20:00   AdventureX       Facebook    \n",
      "4  2023-01-15 19:55:00   ChefCook        Instagram    \n",
      "\n",
      "                                     Hashtags  Retweets     Likes  \\\n",
      "0   #Nature #Park                             -0.922303 -0.916295   \n",
      "1   #Traffic #Morning                         -2.339444 -2.336727   \n",
      "2   #Fitness #Workout                         -0.213733 -0.206079   \n",
      "3   #Travel #Adventure                        -1.914302 -1.981619   \n",
      "4   #Cooking #Food                            -1.347445 -1.271403   \n",
      "\n",
      "        Country      Year     Month       Day      Hour  emotion_encoded  \n",
      "0     USA        0.902984 -1.502582 -0.058718 -0.856774              214  \n",
      "1     Canada     0.902984 -1.502582 -0.058718 -1.829867              195  \n",
      "2   USA          0.902984 -1.502582 -0.058718 -0.126954              214  \n",
      "3     UK         0.902984 -1.502582 -0.058718  0.602866              214  \n",
      "4    Australia   0.902984 -1.502582 -0.058718  0.846139              197  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"sentimentdataset.csv\")\n",
    "\n",
    "# --- Handle Missing Values ---\n",
    "print(\"Missing values before:\\n\", df.isnull().sum())\n",
    "\n",
    "# Drop rows with missing text or label\n",
    "df.dropna(subset=['Text', 'Sentiment'], inplace=True)\n",
    "\n",
    "# Fill missing numerical columns if any\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "print(\"Missing values after:\\n\", df.isnull().sum())\n",
    "\n",
    "# --- Remove Duplicates ---\n",
    "initial_len = len(df)\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f\"Removed {initial_len - len(df)} duplicate rows.\")\n",
    "\n",
    "# --- Outlier Handling (if numerical columns exist) ---\n",
    "# Example: Remove outliers in a column named 'length'\n",
    "if 'length' in df.columns:\n",
    "    q1 = df['length'].quantile(0.25)\n",
    "    q3 = df['length'].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    df = df[(df['length'] >= lower) & (df['length'] <= upper)]\n",
    "    print(\"Outliers removed from 'length' column.\")\n",
    "\n",
    "# --- Label Encoding for Target ---\n",
    "le = LabelEncoder()\n",
    "df['emotion_encoded'] = le.fit_transform(df['Sentiment'])\n",
    "\n",
    "# --- Feature Scaling (if numeric features exist) ---\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Example: scaling if numeric features exist\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "if numeric_cols:\n",
    "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "    print(\"Numerical features scaled.\")\n",
    "\n",
    "# Final structure check\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "174fcd3b-acd2-4eac-b5e3-19ae8b2a0972",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHANGAR\\AppData\\Local\\Temp\\ipykernel_3032\\4231912754.py:45: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(x=\"emotion\", data=df, order=df[\"emotion\"].value_counts().index, palette=\"viridis\")\n",
      "C:\\Users\\SHANGAR\\AppData\\Local\\Temp\\ipykernel_3032\\4231912754.py:49: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "C:\\Users\\SHANGAR\\AppData\\Local\\Temp\\ipykernel_3032\\4231912754.py:53: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x=\"emotion\", y=\"text_length\", data=df, palette=\"Set2\")\n",
      "C:\\Users\\SHANGAR\\AppData\\Local\\Temp\\ipykernel_3032\\4231912754.py:59: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "C:\\Users\\SHANGAR\\AppData\\Local\\Temp\\ipykernel_3032\\4231912754.py:68: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# sentiment_eda_preprocessing.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"sentimentdataset.csv\")  # Make sure this file is in your working directory\n",
    "\n",
    "# Rename columns for consistency\n",
    "df.rename(columns={\"Text\": \"text\", \"Sentiment\": \"emotion\"}, inplace=True)\n",
    "\n",
    "# --- Handle Missing Values ---\n",
    "df.dropna(subset=[\"text\", \"emotion\"], inplace=True)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# --- Remove Duplicates ---\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# --- Add Text Length Feature ---\n",
    "df[\"text_length\"] = df[\"text\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# --- Handle Outliers (Optional for numeric features like text_length) ---\n",
    "q1 = df[\"text_length\"].quantile(0.25)\n",
    "q3 = df[\"text_length\"].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "lower = q1 - 1.5 * iqr\n",
    "upper = q3 + 1.5 * iqr\n",
    "df = df[(df[\"text_length\"] >= lower) & (df[\"text_length\"] <= upper)]\n",
    "\n",
    "# --- Encode Labels ---\n",
    "le = LabelEncoder()\n",
    "df[\"emotion_encoded\"] = le.fit_transform(df[\"emotion\"])\n",
    "\n",
    "# --- Scale Numerical Features ---\n",
    "scaler = StandardScaler()\n",
    "df[[\"text_length_scaled\"]] = scaler.fit_transform(df[[\"text_length\"]])\n",
    "\n",
    "# --- EDA Visuals ---\n",
    "\n",
    "# Emotion Distribution Histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x=\"emotion\", data=df, order=df[\"emotion\"].value_counts().index, palette=\"viridis\")\n",
    "plt.title(\"Distribution of Emotions\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Boxplot of Text Length by Emotion\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=\"emotion\", y=\"text_length\", data=df, palette=\"Set2\")\n",
    "plt.title(\"Text Length by Emotion\")\n",
    "plt.xlabel(\"Emotion\")\n",
    "plt.ylabel(\"Word Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation Heatmap\n",
    "numeric_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "if len(numeric_cols) >= 2:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(df[numeric_cols].corr(), annot=True, cmap=\"coolwarm\")\n",
    "    plt.title(\"Correlation Heatmap\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough numeric columns for a heatmap.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1243359a-cc6b-434b-ab7b-3b2c513dcf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHANGAR\\AppData\\Local\\Temp\\ipykernel_3032\\480926650.py:47: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"sentimentdataset.csv\")\n",
    "df.rename(columns={\"Text\": \"text\", \"Sentiment\": \"emotion\"}, inplace=True)\n",
    "\n",
    "# Drop missing values\n",
    "df.dropna(subset=[\"text\", \"emotion\"], inplace=True)\n",
    "\n",
    "# --- 1. New Feature Creation ---\n",
    "df[\"text_length\"] = df[\"text\"].apply(lambda x: len(str(x).split()))\n",
    "df[\"punctuation_count\"] = df[\"text\"].apply(lambda x: sum([1 for char in str(x) if char in \"!?.\"]))\n",
    "df[\"capital_word_count\"] = df[\"text\"].apply(lambda x: sum([1 for word in str(x).split() if word.isupper()]))\n",
    "\n",
    "# --- 2. Label Encoding ---\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df[\"emotion_encoded\"] = le.fit_transform(df[\"emotion\"])\n",
    "\n",
    "# --- 3. TF-IDF Vectorization ---\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = tfidf.fit_transform(df[\"text\"]).toarray()\n",
    "\n",
    "# Combine with new features\n",
    "X_extra = df[[\"text_length\", \"punctuation_count\", \"capital_word_count\"]].values\n",
    "X_combined = np.hstack((X_tfidf, X_extra))\n",
    "y = df[\"emotion_encoded\"]\n",
    "\n",
    "# --- 4. Feature Scaling ---\n",
    "scaler = StandardScaler()\n",
    "X_combined[:, -3:] = scaler.fit_transform(X_combined[:, -3:])  # Scale extra features\n",
    "\n",
    "\n",
    "\n",
    "# --- 6. Visualization of Impactful New Features ---\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(x=\"emotion\", y=\"text_length\", data=df)\n",
    "plt.title(\"Text Length vs Emotion\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c61eb15c-ad43-4b1d-ab65-2dc03196cf99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# 4. Text vectorization\u001b[39;00m\n\u001b[0;32m     25\u001b[0m tfidf \u001b[38;5;241m=\u001b[39m TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m X \u001b[38;5;241m=\u001b[39m tfidf\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     27\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion_encoded\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# 5. Train/Test split\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2091\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2084\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2085\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2086\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2087\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2088\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2089\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2090\u001b[0m )\n\u001b[1;32m-> 2091\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_transform(raw_documents)\n\u001b[0;32m   2092\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2093\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1372\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1364\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1369\u001b[0m             )\n\u001b[0;32m   1370\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1372\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count_vocab(raw_documents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_vocabulary_)\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1375\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1278\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1276\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[1;32m-> 1278\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1279\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1280\u001b[0m         )\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Load and clean dataset\n",
    "df = pd.read_csv(\"sentimentdataset.csv\")\n",
    "df.rename(columns={\"Text\": \"text\", \"Sentiment\": \"emotion\"}, inplace=True)\n",
    "df.dropna(subset=[\"text\", \"emotion\"], inplace=True)\n",
    "\n",
    "# 2. Filter for selective emotions\n",
    "selected_emotions = [\"joy\", \"sadness\", \"anger\", \"fear\"]\n",
    "df = df[df[\"emotion\"].isin(selected_emotions)]\n",
    "\n",
    "# 3. Encode labels\n",
    "le = LabelEncoder()\n",
    "df[\"emotion_encoded\"] = le.fit_transform(df[\"emotion\"])\n",
    "\n",
    "# 4. Text vectorization\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(df[\"text\"])\n",
    "y = df[\"emotion_encoded\"]\n",
    "\n",
    "# 5. Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. Models to evaluate\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=200),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# 7. Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Classification Report for {name}:\\n\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e2a0e40-5d7d-4f32-a161-f3749f291ce2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 5. Vectorize text using TF-IDF\u001b[39;00m\n\u001b[0;32m     29\u001b[0m tfidf \u001b[38;5;241m=\u001b[39m TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m X \u001b[38;5;241m=\u001b[39m tfidf\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     31\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion_encoded\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# 6. Split into training and testing sets\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2091\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2084\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2085\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2086\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2087\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2088\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2089\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2090\u001b[0m )\n\u001b[1;32m-> 2091\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_transform(raw_documents)\n\u001b[0;32m   2092\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2093\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1372\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1364\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1369\u001b[0m             )\n\u001b[0;32m   1370\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1372\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count_vocab(raw_documents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_vocabulary_)\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1375\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1278\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1276\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[1;32m-> 1278\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1279\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1280\u001b[0m         )\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. Load dataset\n",
    "df = pd.read_csv(\"sentimentdataset.csv\")\n",
    "df.rename(columns={\"Text\": \"text\", \"Sentiment\": \"emotion\"}, inplace=True)\n",
    "\n",
    "# 2. Filter only desired emotions\n",
    "selected_emotions = [\"joy\", \"sadness\", \"anger\", \"fear\"]\n",
    "df = df[df[\"emotion\"].isin(selected_emotions)]\n",
    "\n",
    "# 3. Clean and validate text column\n",
    "df[\"text\"] = df[\"text\"].astype(str).str.strip()\n",
    "df = df[df[\"text\"].str.len() > 0]  # Remove empty strings\n",
    "df = df[~df[\"text\"].isin(ENGLISH_STOP_WORDS)]  # Optional: remove entries that are only stopwords\n",
    "\n",
    "# 4. Encode target labels\n",
    "le = LabelEncoder()\n",
    "df[\"emotion_encoded\"] = le.fit_transform(df[\"emotion\"])\n",
    "\n",
    "# 5. Vectorize text using TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(df[\"text\"])\n",
    "y = df[\"emotion_encoded\"]\n",
    "\n",
    "# 6. Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 7. Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=200),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# 8. Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\nClassification Report for {name}:\\n\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f2d1476-c811-41f1-be06-02bbda761af6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'emotion'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'emotion'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 36\u001b[0m\n\u001b[0;32m     29\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogistic Regression\u001b[39m\u001b[38;5;124m\"\u001b[39m: LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m),\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaive Bayes\u001b[39m\u001b[38;5;124m\"\u001b[39m: MultinomialNB(),\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m\"\u001b[39m: RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     33\u001b[0m }\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# 8. Train and evaluate each model\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m target_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munique())  \u001b[38;5;66;03m# Get unique emotion names in consistent order\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Training: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'emotion'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. Load dataset\n",
    "df = pd.read_csv(\"sentimentdataset.csv\")\n",
    "df.rename(columns={\"Text\": \"text\", \"Sentiment\": \"emotion\"}, inplace=True)\n",
    "\n",
    "# 2. Filter only desired emotions\n",
    "selected_emotions = [\"joy\", \"sadness\", \"anger\", \"fear\"]\n",
    "df = df[df[\"emotion\"].isin(selected_emotions)]\n",
    "\n",
    "# 3. Clean and validate text column\n",
    "df[\"text\"] = df[\"text\"].astype(str).str.strip()\n",
    "df = df[df[\"text\"].apply(lambda x: len(x.split()) > 1)]  # Remove rows with <= 1 word\n",
    "\n",
    "\n",
    "\n",
    "# 6. Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 7. Define models to test\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=200),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# 8. Train and evaluate each model\n",
    "target_names = sorted(df[\"emotion\"].unique())  # Get unique emotion names in consistent order\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Classification Report for {name}:\\n\")\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "141b5a23-5123-4282-bf51-0104204fb87d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'emotion'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'emotion'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Encode emotion labels\u001b[39;00m\n\u001b[0;32m     24\u001b[0m le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m---> 25\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion_encoded\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Vectorize text using TF-IDF\u001b[39;00m\n\u001b[0;32m     28\u001b[0m tfidf \u001b[38;5;241m=\u001b[39m TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m, stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'emotion'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"sentimentdataset.csv\")\n",
    "df.rename(columns={\"Text\": \"text\", \"Sentiment\": \"emotion\"}, inplace=True)\n",
    "\n",
    "# Filter for selective emotions\n",
    "selected_emotions = [\"joy\", \"sadness\", \"anger\", \"fear\"]\n",
    "df = df[df[\"emotion\"].isin(selected_emotions)]\n",
    "\n",
    "# Clean and validate text column\n",
    "df[\"text\"] = df[\"text\"].astype(str).str.strip()\n",
    "df = df[df[\"text\"].apply(lambda x: len(x.split()) > 1)]  # Keep only texts with more than one word\n",
    "\n",
    "# Encode emotion labels\n",
    "le = LabelEncoder()\n",
    "df[\"emotion_encoded\"] = le.fit_transform(df[\"emotion\"])\n",
    "\n",
    "# Vectorize text using TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words=None)\n",
    "X = tfidf.fit_transform(df[\"text\"])\n",
    "y = df[\"emotion_encoded\"]\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=200),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Get class names\n",
    "target_names = le.classes_\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\nClassification Report for {name}:\\n\")\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f30f6db-25e7-4ac8-aeda-0bfb47dd35d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LabelEncoder' object has no attribute 'classes_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 45\u001b[0m\n\u001b[0;32m     35\u001b[0m results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m: name,\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: acc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m: rmse\n\u001b[0;32m     42\u001b[0m })\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred, target_names\u001b[38;5;241m=\u001b[39mle\u001b[38;5;241m.\u001b[39mclasses_))\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Confusion Matrix\u001b[39;00m\n\u001b[0;32m     48\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_pred)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LabelEncoder' object has no attribute 'classes_'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    mean_squared_error\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Assume df, X_train, X_test, y_train, y_test, models are already defined\n",
    "# And label encoder was already applied -> le\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    prec = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "    rec = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1-Score\": f1,\n",
    "        \"RMSE\": rmse\n",
    "    })\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title(f\"Confusion Matrix - {name}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve (for models that support predict_proba)\n",
    "    if y_proba is not None and len(le.classes_) == 2:\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba[:, 1])\n",
    "        auc = roc_auc_score(y_test, y_proba[:, 1])\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label=f\"{name} (AUC = {auc:.2f})\")\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "        plt.title(\"ROC Curve\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Model Comparison Table\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n=== Model Comparison Table ===\")\n",
    "print(results_df.sort_values(by=\"F1-Score\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1c220fd-3e5e-4260-ab5f-34a0cc6613b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SHANGAR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0.1  Unnamed: 0  \\\n",
      "0             0           0   \n",
      "1             1           1   \n",
      "2             2           2   \n",
      "3             3           3   \n",
      "4             4           4   \n",
      "\n",
      "                                                Text    Sentiment  \\\n",
      "0   Enjoying a beautiful day at the park!        ...   Positive     \n",
      "1   Traffic was terrible this morning.           ...   Negative     \n",
      "2   Just finished an amazing workout! 💪          ...   Positive     \n",
      "3   Excited about the upcoming weekend getaway!  ...   Positive     \n",
      "4   Trying out a new recipe for dinner tonight.  ...   Neutral      \n",
      "\n",
      "             Timestamp            User     Platform  \\\n",
      "0  2023-01-15 12:30:00   User123          Twitter     \n",
      "1  2023-01-15 08:45:00   CommuterX        Twitter     \n",
      "2  2023-01-15 15:45:00   FitnessFan      Instagram    \n",
      "3  2023-01-15 18:20:00   AdventureX       Facebook    \n",
      "4  2023-01-15 19:55:00   ChefCook        Instagram    \n",
      "\n",
      "                                     Hashtags  Retweets  Likes       Country  \\\n",
      "0   #Nature #Park                                  15.0   30.0     USA         \n",
      "1   #Traffic #Morning                               5.0   10.0     Canada      \n",
      "2   #Fitness #Workout                              20.0   40.0   USA           \n",
      "3   #Travel #Adventure                              8.0   15.0     UK          \n",
      "4   #Cooking #Food                                 12.0   25.0    Australia    \n",
      "\n",
      "   Year  Month  Day  Hour  \n",
      "0  2023      1   15    12  \n",
      "1  2023      1   15     8  \n",
      "2  2023      1   15    15  \n",
      "3  2023      1   15    18  \n",
      "4  2023      1   15    19  \n",
      "Accuracy: 0.11564625850340136\n",
      "\n",
      "Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "         Acceptance          0.00      0.00      0.00         2\n",
      "           Admiration        0.00      0.00      0.00         1\n",
      "        Admiration           0.00      0.00      0.00         1\n",
      "         Affection           0.00      0.00      0.00         1\n",
      "      Ambivalence            0.00      0.00      0.00         1\n",
      "         Anger               0.00      0.00      0.00         1\n",
      "        Anticipation         0.00      0.00      0.00         1\n",
      "        Arousal              0.00      0.00      0.00         3\n",
      "                  Awe        0.00      0.00      0.00         1\n",
      "         Awe                 0.00      0.00      0.00         1\n",
      "                  Bad        0.00      0.00      0.00         1\n",
      "             Betrayal        0.00      0.00      0.00         2\n",
      "        Betrayal             0.00      0.00      0.00         1\n",
      "         Bitter              0.00      0.00      0.00         1\n",
      "           Bitterness        0.00      0.00      0.00         1\n",
      "          Bittersweet        0.00      0.00      0.00         1\n",
      "              Boredom        0.00      0.00      0.00         1\n",
      "         Calmness            0.00      0.00      0.00         1\n",
      "          Captivation        0.00      0.00      0.00         1\n",
      "     Celestial Wonder        0.00      0.00      0.00         1\n",
      "             Colorful        0.00      0.00      0.00         1\n",
      "      Confusion              0.00      0.00      0.00         3\n",
      "           Connection        0.00      0.00      0.00         1\n",
      "        Contemplation        0.00      0.00      0.00         1\n",
      "          Contentment        0.00      0.00      0.00         3\n",
      "        Contentment          0.00      0.00      0.00         1\n",
      "         Coziness            0.00      0.00      0.00         1\n",
      "         Creativity          0.00      0.00      0.00         1\n",
      "            Curiosity        0.00      0.00      0.00         2\n",
      "          Curiosity          0.00      0.00      0.00         1\n",
      "      Curiosity              0.00      0.00      0.00         2\n",
      "           Desolation        0.00      0.00      0.00         1\n",
      "           Devastated        0.00      0.00      0.00         2\n",
      "              Disgust        0.00      0.00      0.00         1\n",
      "         Disgust             0.00      0.00      0.00         2\n",
      "        Elation              0.00      0.00      0.00         3\n",
      "             Elegance        0.00      0.00      0.00         1\n",
      "          Embarrassed        0.00      0.00      0.00         1\n",
      "       EmotionalStorm        0.00      0.00      0.00         1\n",
      "        Empowerment          0.00      0.00      0.00         1\n",
      "         Enjoyment           0.00      0.00      0.00         2\n",
      "           Enthusiasm        0.00      0.00      0.00         1\n",
      "              Envious        0.00      0.00      0.00         2\n",
      "  Envisioning History        0.00      0.00      0.00         1\n",
      "         Euphoria            0.00      0.00      0.00         1\n",
      "           Excitement        0.09      0.33      0.14         3\n",
      "         Excitement          0.00      0.00      0.00         3\n",
      "        Excitement           0.00      0.00      0.00         1\n",
      "         Fear                0.00      0.00      0.00         1\n",
      "              Fearful        0.00      0.00      0.00         1\n",
      "           Frustrated        0.00      0.00      0.00         1\n",
      "          Frustration        0.00      0.00      0.00         3\n",
      "         Fulfillment         0.00      0.00      0.00         2\n",
      "             Grateful        0.00      0.00      0.00         1\n",
      "      Grief                  0.00      0.00      0.00         1\n",
      "                Happy        0.00      0.00      0.00         6\n",
      "                 Hate        0.00      0.00      0.00         2\n",
      "           Heartbreak        0.00      0.00      0.00         2\n",
      "              Hopeful        1.00      1.00      1.00         1\n",
      "        InnerJourney         0.00      0.00      0.00         1\n",
      "        Inspiration          0.00      0.00      0.00         1\n",
      "             Inspired        0.00      0.00      0.00         1\n",
      "            Isolation        0.00      0.00      0.00         1\n",
      "          Jealousy           0.00      0.00      0.00         1\n",
      "                  Joy        0.13      0.75      0.22         8\n",
      "         Joy                 0.00      0.00      0.00         1\n",
      "        JoyfulReunion        0.00      0.00      0.00         1\n",
      "         Kind                0.00      0.00      0.00         1\n",
      "           Loneliness        0.00      0.00      0.00         1\n",
      "      Loneliness             0.00      0.00      0.00         1\n",
      "             LostLove        0.00      0.00      0.00         1\n",
      "      Melancholy             0.00      0.00      0.00         2\n",
      "       Miscalculation        0.00      0.00      0.00         1\n",
      "              Neutral        0.00      0.00      0.00         1\n",
      "        Nostalgia            0.00      0.00      0.00         1\n",
      "      Nostalgia              0.00      0.00      0.00         1\n",
      "      Numbness               0.00      0.00      0.00         1\n",
      "          Overwhelmed        0.00      0.00      0.00         1\n",
      "              Playful        0.00      0.00      0.00         2\n",
      "            Positive         0.10      1.00      0.18         9\n",
      "                Proud        0.00      0.00      0.00         1\n",
      "        Reflection           0.00      0.00      0.00         1\n",
      "       Regret                0.00      0.00      0.00         1\n",
      "           Resilience        0.00      0.00      0.00         1\n",
      "            Reverence        0.00      0.00      0.00         1\n",
      "         Sadness             0.00      0.00      0.00         2\n",
      "        Satisfaction         0.00      0.00      0.00         1\n",
      "             Serenity        0.00      0.00      0.00         2\n",
      "      Serenity               0.00      0.00      0.00         2\n",
      "             Solitude        0.00      0.00      0.00         1\n",
      "          Sorrow             0.00      0.00      0.00         1\n",
      "         Spark               0.00      0.00      0.00         1\n",
      "         Surprise            0.00      0.00      0.00         1\n",
      "        Thrill               0.00      0.00      0.00         1\n",
      "             Vibrancy        0.00      0.00      0.00         1\n",
      " Whispers of the Past        0.00      0.00      0.00         1\n",
      "                 Zest        0.00      0.00      0.00         1\n",
      "\n",
      "              accuracy                           0.12       147\n",
      "             macro avg       0.01      0.03      0.02       147\n",
      "          weighted avg       0.02      0.12      0.03       147\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"sentimentdataset.csv\")\n",
    "\n",
    "# Preview the data\n",
    "print(df.head())\n",
    "\n",
    "# Assuming the columns are 'text' and 'sentiment'. Adjust if needed.\n",
    "text_column = 'Text'       # change to the correct column name\n",
    "label_column = 'Sentiment' # change to the correct column name\n",
    "\n",
    "# Clean text data\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)  # Remove URLs\n",
    "    text = re.sub(r'\\@w+|\\#','', text)  # Remove mentions and hashtags\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)  # Remove punctuation/numbers\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    ps = PorterStemmer()\n",
    "    tokens = [ps.stem(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df[text_column] = df[text_column].astype(str).apply(preprocess)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[text_column], df[label_column], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Model training\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Prediction and evaluation\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c392d19-c90d-4033-9222-1f77bc46905f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SHANGAR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ' Curiosity '",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 68\u001b[0m\n\u001b[0;32m     66\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[0;32m     67\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m rmse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 Score (Weighted): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:502\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    492\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    493\u001b[0m         (\n\u001b[0;32m    494\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquared\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated in version 1.4 and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[1;32m--> 502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[0;32m    503\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[0;32m    504\u001b[0m         )\n\u001b[0;32m    506\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    507\u001b[0m     y_true, y_pred, multioutput\n\u001b[0;32m    508\u001b[0m )\n\u001b[0;32m    509\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:581\u001b[0m, in \u001b[0;36mroot_mean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    523\u001b[0m     {\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    532\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m ):\n\u001b[0;32m    534\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Root mean squared error regression loss.\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \n\u001b[0;32m    536\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;124;03m    0.822...\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    580\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\n\u001b[1;32m--> 581\u001b[0m         mean_squared_error(\n\u001b[0;32m    582\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    583\u001b[0m         )\n\u001b[0;32m    584\u001b[0m     )\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(multioutput, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    587\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m multioutput \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:506\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[0;32m    502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[0;32m    503\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[0;32m    504\u001b[0m         )\n\u001b[1;32m--> 506\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    507\u001b[0m     y_true, y_pred, multioutput\n\u001b[0;32m    508\u001b[0m )\n\u001b[0;32m    509\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    510\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:112\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[0;32m    109\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, multioutput, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m    111\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m--> 112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1012\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1012\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1015\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1016\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:751\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    749\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 751\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    753\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1031\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[0;32m    983\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1030\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1031\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   1033\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ' Curiosity '"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    mean_squared_error,\n",
    "    classification_report,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"sentimentdataset.csv\")\n",
    "\n",
    "# Adjust column names as needed\n",
    "text_column = 'Text'       # Replace with actual column name\n",
    "label_column = 'Sentiment' # Replace with actual column name\n",
    "\n",
    "# Preprocess text\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    ps = PorterStemmer()\n",
    "    tokens = [ps.stem(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df[text_column] = df[text_column].astype(str).apply(preprocess)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[text_column], df[label_column], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Vectorize text\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Train model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test_vec)\n",
    "y_proba = model.predict_proba(X_test_vec)\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score (Weighted): {f1:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve (only for binary classification)\n",
    "if len(model.classes_) == 2:\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba[:, 1], pos_label=model.classes_[1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"ROC Curve is not supported for multi-class without binarization.\")\n",
    "\n",
    "# Error Analysis\n",
    "errors = pd.DataFrame({\n",
    "    'Text': X_test,\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred\n",
    "})\n",
    "errors = errors[errors['Actual'] != errors['Predicted']]\n",
    "print(\"Sample Misclassifications:\\n\", errors.head())\n",
    "\n",
    "# Optional: Model comparison placeholder\n",
    "# You can extend this if you train more models\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Naive Bayes'],\n",
    "    'Accuracy': [accuracy],\n",
    "    'F1 Score': [f1],\n",
    "    'RMSE': [rmse]\n",
    "})\n",
    "print(\"\\nModel Comparison:\\n\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1eb6b4b3-7bd9-4e1c-9009-a228142c3985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ' Curiosity '",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[0;32m      4\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 'weighted' handles class imbalance\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m rmse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 Score (Weighted): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:502\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    492\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    493\u001b[0m         (\n\u001b[0;32m    494\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquared\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated in version 1.4 and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[1;32m--> 502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[0;32m    503\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[0;32m    504\u001b[0m         )\n\u001b[0;32m    506\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    507\u001b[0m     y_true, y_pred, multioutput\n\u001b[0;32m    508\u001b[0m )\n\u001b[0;32m    509\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:581\u001b[0m, in \u001b[0;36mroot_mean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    523\u001b[0m     {\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    532\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m ):\n\u001b[0;32m    534\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Root mean squared error regression loss.\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \n\u001b[0;32m    536\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;124;03m    0.822...\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    580\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\n\u001b[1;32m--> 581\u001b[0m         mean_squared_error(\n\u001b[0;32m    582\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    583\u001b[0m         )\n\u001b[0;32m    584\u001b[0m     )\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(multioutput, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    587\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m multioutput \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:506\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[0;32m    502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[0;32m    503\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[0;32m    504\u001b[0m         )\n\u001b[1;32m--> 506\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    507\u001b[0m     y_true, y_pred, multioutput\n\u001b[0;32m    508\u001b[0m )\n\u001b[0;32m    509\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    510\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:112\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[0;32m    109\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, multioutput, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m    111\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m--> 112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1012\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1012\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1015\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1016\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:751\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    749\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 751\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    753\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1031\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[0;32m    983\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1030\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1031\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   1033\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ' Curiosity '"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, mean_squared_error, roc_curve, auc\n",
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # 'weighted' handles class imbalance\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score (Weighted): {f1:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "736297be-ff2b-41c3-b1c9-fcedbb280d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1088\n",
      "F1 Score (Weighted): 0.0312\n",
      "\n",
      "Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "         Acceptance          0.00      0.00      0.00         2\n",
      "           Admiration        0.00      0.00      0.00         1\n",
      "        Admiration           0.00      0.00      0.00         1\n",
      "         Affection           0.00      0.00      0.00         1\n",
      "      Ambivalence            0.00      0.00      0.00         1\n",
      "         Anger               0.00      0.00      0.00         1\n",
      "        Anticipation         0.00      0.00      0.00         1\n",
      "        Arousal              0.00      0.00      0.00         3\n",
      "                  Awe        0.00      0.00      0.00         1\n",
      "         Awe                 0.00      0.00      0.00         1\n",
      "                  Bad        0.00      0.00      0.00         1\n",
      "             Betrayal        0.00      0.00      0.00         2\n",
      "        Betrayal             0.00      0.00      0.00         1\n",
      "         Bitter              0.00      0.00      0.00         1\n",
      "           Bitterness        0.00      0.00      0.00         1\n",
      "          Bittersweet        0.00      0.00      0.00         1\n",
      "              Boredom        0.00      0.00      0.00         1\n",
      "         Calmness            0.00      0.00      0.00         1\n",
      "          Captivation        0.00      0.00      0.00         1\n",
      "     Celestial Wonder        0.00      0.00      0.00         1\n",
      "             Colorful        0.00      0.00      0.00         1\n",
      "      Confusion              0.00      0.00      0.00         3\n",
      "           Connection        0.00      0.00      0.00         1\n",
      "        Contemplation        0.00      0.00      0.00         1\n",
      "          Contentment        0.00      0.00      0.00         3\n",
      "        Contentment          0.00      0.00      0.00         1\n",
      "         Coziness            0.00      0.00      0.00         1\n",
      "         Creativity          0.00      0.00      0.00         1\n",
      "            Curiosity        0.00      0.00      0.00         2\n",
      "          Curiosity          0.00      0.00      0.00         1\n",
      "      Curiosity              0.00      0.00      0.00         2\n",
      "           Desolation        0.00      0.00      0.00         1\n",
      "           Devastated        0.00      0.00      0.00         2\n",
      "              Disgust        0.00      0.00      0.00         1\n",
      "         Disgust             0.00      0.00      0.00         2\n",
      "        Elation              0.00      0.00      0.00         3\n",
      "             Elegance        0.00      0.00      0.00         1\n",
      "          Embarrassed        0.00      0.00      0.00         1\n",
      "       EmotionalStorm        0.00      0.00      0.00         1\n",
      "        Empowerment          0.00      0.00      0.00         1\n",
      "         Enjoyment           0.00      0.00      0.00         2\n",
      "           Enthusiasm        0.00      0.00      0.00         1\n",
      "              Envious        0.00      0.00      0.00         2\n",
      "  Envisioning History        0.00      0.00      0.00         1\n",
      "         Euphoria            0.00      0.00      0.00         1\n",
      "           Excitement        0.08      0.33      0.12         3\n",
      "         Excitement          0.00      0.00      0.00         3\n",
      "        Excitement           0.00      0.00      0.00         1\n",
      "         Fear                0.00      0.00      0.00         1\n",
      "              Fearful        0.00      0.00      0.00         1\n",
      "           Frustrated        0.00      0.00      0.00         1\n",
      "          Frustration        0.00      0.00      0.00         3\n",
      "         Fulfillment         0.00      0.00      0.00         2\n",
      "             Grateful        0.00      0.00      0.00         1\n",
      "      Grief                  0.00      0.00      0.00         1\n",
      "                Happy        0.00      0.00      0.00         6\n",
      "                 Hate        0.00      0.00      0.00         2\n",
      "           Heartbreak        0.00      0.00      0.00         2\n",
      "              Hopeful        1.00      1.00      1.00         1\n",
      "        InnerJourney         0.00      0.00      0.00         1\n",
      "        Inspiration          0.00      0.00      0.00         1\n",
      "             Inspired        0.00      0.00      0.00         1\n",
      "            Isolation        0.00      0.00      0.00         1\n",
      "          Jealousy           0.00      0.00      0.00         1\n",
      "                  Joy        0.12      0.75      0.20         8\n",
      "         Joy                 0.00      0.00      0.00         1\n",
      "        JoyfulReunion        0.00      0.00      0.00         1\n",
      "         Kind                0.00      0.00      0.00         1\n",
      "           Loneliness        0.00      0.00      0.00         1\n",
      "      Loneliness             0.00      0.00      0.00         1\n",
      "             LostLove        0.00      0.00      0.00         1\n",
      "      Melancholy             0.00      0.00      0.00         2\n",
      "       Miscalculation        0.00      0.00      0.00         1\n",
      "              Neutral        0.00      0.00      0.00         1\n",
      "        Nostalgia            0.00      0.00      0.00         1\n",
      "      Nostalgia              0.00      0.00      0.00         1\n",
      "      Numbness               0.00      0.00      0.00         1\n",
      "          Overwhelmed        0.00      0.00      0.00         1\n",
      "              Playful        0.00      0.00      0.00         2\n",
      "            Positive         0.10      0.89      0.18         9\n",
      "                Proud        0.00      0.00      0.00         1\n",
      "        Reflection           0.00      0.00      0.00         1\n",
      "       Regret                0.00      0.00      0.00         1\n",
      "           Resilience        0.00      0.00      0.00         1\n",
      "            Reverence        0.00      0.00      0.00         1\n",
      "         Sadness             0.00      0.00      0.00         2\n",
      "        Satisfaction         0.00      0.00      0.00         1\n",
      "             Serenity        0.00      0.00      0.00         2\n",
      "      Serenity               0.00      0.00      0.00         2\n",
      "             Solitude        0.00      0.00      0.00         1\n",
      "          Sorrow             0.00      0.00      0.00         1\n",
      "         Spark               0.00      0.00      0.00         1\n",
      "         Surprise            0.00      0.00      0.00         1\n",
      "        Thrill               0.00      0.00      0.00         1\n",
      "             Vibrancy        0.00      0.00      0.00         1\n",
      " Whispers of the Past        0.00      0.00      0.00         1\n",
      "                 Zest        0.00      0.00      0.00         1\n",
      "\n",
      "              accuracy                           0.11       147\n",
      "             macro avg       0.01      0.03      0.02       147\n",
      "          weighted avg       0.02      0.11      0.03       147\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Curve skipped: multi-class ROC not visualized here.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHANGAR\\AppData\\Local\\Temp\\ipykernel_3032\\429692536.py:24: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    classification_report, accuracy_score, f1_score, confusion_matrix, roc_auc_score)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # 'weighted' handles imbalance\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score (Weighted): {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=model.classes_, yticklabels=model.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "# ROC Curve (if binary or one-vs-rest)\n",
    "if len(model.classes_) == 2:\n",
    "    y_test_bin = label_binarize(y_test, classes=model.classes_)\n",
    "    y_pred_proba = model.predict_proba(X_test_vec)[:, 1]\n",
    "    auc = roc_auc_score(y_test_bin, y_pred_proba)\n",
    "    print(f\"ROC AUC Score: {auc:.4f}\")\n",
    "else:\n",
    "    print(\"ROC Curve skipped: multi-class ROC not visualized here.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c9262e7-2e90-4542-b12b-3f09ba716e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\AppData\\Local\\Temp\\ipykernel_3032\\4007006949.py:41: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Binarize the labels\n",
    "classes = model.classes_  # or: np.unique(y)\n",
    "y_test_bin = label_binarize(y_test, classes=classes)\n",
    "n_classes = y_test_bin.shape[1]\n",
    "\n",
    "# Predict probabilities for each class\n",
    "y_score = model.predict_proba(X_test_vec)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"Class {classes[i]} (AUC = {roc_auc[i]:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Random Guess\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Multi-Class ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb344f7a-eea9-4eaf-81d4-d8c64f840d9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'emotion'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'emotion'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# 4. Encode emotion labels\u001b[39;00m\n\u001b[0;32m     25\u001b[0m le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m---> 26\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion_encoded\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 5. TF-IDF Vectorization\u001b[39;00m\n\u001b[0;32m     29\u001b[0m tfidf \u001b[38;5;241m=\u001b[39m TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'emotion'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 1. Load dataset\n",
    "df = pd.read_csv(\"sentimentdataset.csv\")\n",
    "df.rename(columns={\"Text\": \"text\", \"Sentiment\": \"emotion\"}, inplace=True)\n",
    "\n",
    "# 2. Select specific emotions\n",
    "selected_emotions = [\"joy\", \"sadness\", \"anger\", \"fear\"]\n",
    "df = df[df[\"emotion\"].isin(selected_emotions)]\n",
    "\n",
    "# 3. Clean text column\n",
    "df[\"text\"] = df[\"text\"].astype(str).str.strip()\n",
    "df = df[df[\"text\"].apply(lambda x: len(x.split()) > 1)]\n",
    "\n",
    "# 4. Encode emotion labels\n",
    "le = LabelEncoder()\n",
    "df[\"emotion_encoded\"] = le.fit_transform(df[\"emotion\"])\n",
    "\n",
    "# 5. TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(df[\"text\"])\n",
    "y = df[\"emotion_encoded\"]\n",
    "\n",
    "# 6. Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 7. Define models with reasons\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=200),  # 🔹 Baseline model: fast, interpretable\n",
    "    \"Naive Bayes\": MultinomialNB(),                           # 🔹 Probabilistic, good for text frequency\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),# 🔹 Handles non-linear patterns well\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),        # 🔹 Advanced ensemble, often very accurate\n",
    "    \"Support Vector Machine\": SVC(kernel='linear')            # 🔹 Great for high-dimensional TF-IDF text\n",
    "}\n",
    "\n",
    "# 8. Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
