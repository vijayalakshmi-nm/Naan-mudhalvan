{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "760b683c-6413-40c5-beb5-623af5ec5f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025-05-12 21:53:36.421 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-05-12 21:53:36.427 Session state does not function when running a script without `streamlit run`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "         Acceptance          0.00      0.00      0.00         2\n",
      "      Acceptance             0.00      0.00      0.00         0\n",
      "           Admiration        0.00      0.00      0.00         1\n",
      "        Admiration           0.00      0.00      0.00         1\n",
      "         Affection           0.00      0.00      0.00         1\n",
      "      Ambivalence            0.00      0.00      0.00         1\n",
      "         Anger               0.00      0.00      0.00         1\n",
      "        Anticipation         0.00      0.00      0.00         1\n",
      "        Arousal              0.00      0.00      0.00         3\n",
      "                  Awe        0.00      0.00      0.00         1\n",
      "         Awe                 0.00      0.00      0.00         1\n",
      "                  Bad        0.00      0.00      0.00         1\n",
      "             Betrayal        0.00      0.00      0.00         2\n",
      "        Betrayal             0.00      0.00      0.00         1\n",
      "         Bitter              0.00      0.00      0.00         1\n",
      "           Bitterness        0.00      0.00      0.00         1\n",
      "          Bittersweet        0.00      0.00      0.00         1\n",
      "              Boredom        0.00      0.00      0.00         1\n",
      "         Calmness            0.00      0.00      0.00         1\n",
      "          Captivation        0.00      0.00      0.00         1\n",
      "     Celestial Wonder        0.00      0.00      0.00         1\n",
      "             Colorful        0.00      0.00      0.00         1\n",
      "      Confusion              0.00      0.00      0.00         3\n",
      "           Connection        0.00      0.00      0.00         1\n",
      "        Contemplation        0.00      0.00      0.00         1\n",
      "          Contentment        0.00      0.00      0.00         3\n",
      "        Contentment          0.00      0.00      0.00         1\n",
      "         Coziness            0.00      0.00      0.00         1\n",
      "         Creativity          0.00      0.00      0.00         1\n",
      "            Curiosity        0.00      0.00      0.00         2\n",
      "          Curiosity          0.00      0.00      0.00         1\n",
      "      Curiosity              0.00      0.00      0.00         2\n",
      "           Desolation        0.00      0.00      0.00         1\n",
      "           Devastated        0.00      0.00      0.00         2\n",
      "              Disgust        0.00      0.00      0.00         1\n",
      "         Disgust             0.00      0.00      0.00         2\n",
      "        Elation              0.00      0.00      0.00         3\n",
      "             Elegance        0.00      0.00      0.00         1\n",
      "          Embarrassed        0.00      0.00      0.00         1\n",
      "       EmotionalStorm        0.00      0.00      0.00         1\n",
      "        Empowerment          0.00      0.00      0.00         1\n",
      "         Enjoyment           0.00      0.00      0.00         2\n",
      "           Enthusiasm        0.00      0.00      0.00         1\n",
      "              Envious        0.00      0.00      0.00         2\n",
      "  Envisioning History        0.00      0.00      0.00         1\n",
      "         Euphoria            0.00      0.00      0.00         1\n",
      "           Excitement        0.05      0.33      0.08         3\n",
      "         Excitement          0.00      0.00      0.00         3\n",
      "        Excitement           0.00      0.00      0.00         1\n",
      "         Fear                0.00      0.00      0.00         1\n",
      "              Fearful        0.00      0.00      0.00         1\n",
      "           Frustrated        0.00      0.00      0.00         1\n",
      "          Frustration        0.00      0.00      0.00         3\n",
      "         Fulfillment         0.00      0.00      0.00         2\n",
      "             Grateful        0.00      0.00      0.00         1\n",
      "      Grief                  0.00      0.00      0.00         1\n",
      "                Happy        0.00      0.00      0.00         6\n",
      "                 Hate        0.00      0.00      0.00         2\n",
      "           Heartbreak        0.00      0.00      0.00         2\n",
      "              Hopeful        1.00      1.00      1.00         1\n",
      "        InnerJourney         0.00      0.00      0.00         1\n",
      "        Inspiration          0.00      0.00      0.00         1\n",
      "             Inspired        0.00      0.00      0.00         1\n",
      "            Isolation        0.00      0.00      0.00         1\n",
      "          Jealousy           0.00      0.00      0.00         1\n",
      "                  Joy        0.12      1.00      0.22         8\n",
      "         Joy                 0.00      0.00      0.00         1\n",
      "        JoyfulReunion        0.00      0.00      0.00         1\n",
      "         Kind                0.00      0.00      0.00         1\n",
      "           Loneliness        0.00      0.00      0.00         1\n",
      "      Loneliness             0.00      0.00      0.00         1\n",
      "             LostLove        0.00      0.00      0.00         1\n",
      "      Melancholy             0.00      0.00      0.00         2\n",
      "       Miscalculation        0.00      0.00      0.00         1\n",
      "              Neutral        0.00      0.00      0.00         1\n",
      "        Nostalgia            0.00      0.00      0.00         1\n",
      "      Nostalgia              0.00      0.00      0.00         1\n",
      "      Numbness               0.00      0.00      0.00         1\n",
      "          Overwhelmed        0.00      0.00      0.00         1\n",
      "              Playful        0.00      0.00      0.00         2\n",
      "            Positive         0.14      0.89      0.24         9\n",
      "                Proud        0.00      0.00      0.00         1\n",
      "        Reflection           0.00      0.00      0.00         1\n",
      "       Regret                0.00      0.00      0.00         1\n",
      "           Resilience        0.00      0.00      0.00         1\n",
      "            Reverence        0.00      0.00      0.00         1\n",
      "         Sadness             0.00      0.00      0.00         2\n",
      "        Satisfaction         0.00      0.00      0.00         1\n",
      "             Serenity        0.00      0.00      0.00         2\n",
      "      Serenity               0.00      0.00      0.00         2\n",
      "             Solitude        0.00      0.00      0.00         1\n",
      "          Sorrow             0.00      0.00      0.00         1\n",
      "         Spark               0.00      0.00      0.00         1\n",
      "         Surprise            0.00      0.00      0.00         1\n",
      "        Thrill               0.00      0.00      0.00         1\n",
      "             Vibrancy        0.00      0.00      0.00         1\n",
      " Whispers of the Past        0.00      0.00      0.00         1\n",
      "                 Zest        0.00      0.00      0.00         1\n",
      "\n",
      "              accuracy                           0.12       147\n",
      "             macro avg       0.01      0.03      0.02       147\n",
      "          weighted avg       0.02      0.12      0.03       147\n",
      "\n",
      "Confusion Matrix:\n",
      " [[0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# sentiment_analysis.py\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import streamlit as st\n",
    "\n",
    "# 1. Load Dataset\n",
    "df = pd.read_csv(\"sentimentdataset.csv\")  # Make sure your CSV has 'text' and 'emotion' columns\n",
    "\n",
    "# 2. Preprocessing Function\n",
    "def clean_text(Text):\n",
    "    text = re.sub(r\"http\\\\S+\", \"\", Text)\n",
    "    text = re.sub(r\"@[A-Za-z0-9_]+\", \"\", Text)\n",
    "    text = re.sub(r\"#[A-Za-z0-9_]+\", \"\", Text)\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text\n",
    "\n",
    "df[\"clean_text\"] = df[\"Text\"].apply(clean_text)\n",
    "\n",
    "# 3. Vectorization\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(df[\"clean_text\"])\n",
    "y = df[\"Sentiment\"]\n",
    "\n",
    "# 4. Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 5. Train Logistic Regression Model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 6. Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 7. Streamlit Web App\n",
    "st.title(\"ðŸ§  Emotion Detector from Social Media Text\")\n",
    "user_input = st.text_area(\"Enter a tweet or comment:\")\n",
    "\n",
    "if st.button(\"Analyze Emotion\"):\n",
    "    cleaned = clean_text(user_input)\n",
    "    vectorized = tfidf.transform([cleaned])\n",
    "    prediction = model.predict(vectorized)[0]\n",
    "    st.success(f\"Predicted Emotion: **{prediction}**\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6de440e7-f6dd-4dcf-b944-193a1c73105b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 732\n",
      "Number of columns: 15\n",
      "\n",
      "Column Names: ['Unnamed: 0.1', 'Unnamed: 0', 'Text', 'Sentiment', 'Timestamp', 'User', 'Platform', 'Hashtags', 'Retweets', 'Likes', 'Country', 'Year', 'Month', 'Day', 'Hour']\n",
      "\n",
      "First 5 records:\n",
      "   Unnamed: 0.1  Unnamed: 0  \\\n",
      "0             0           0   \n",
      "1             1           1   \n",
      "2             2           2   \n",
      "3             3           3   \n",
      "4             4           4   \n",
      "\n",
      "                                                Text    Sentiment  \\\n",
      "0   Enjoying a beautiful day at the park!        ...   Positive     \n",
      "1   Traffic was terrible this morning.           ...   Negative     \n",
      "2   Just finished an amazing workout! ðŸ’ª          ...   Positive     \n",
      "3   Excited about the upcoming weekend getaway!  ...   Positive     \n",
      "4   Trying out a new recipe for dinner tonight.  ...   Neutral      \n",
      "\n",
      "             Timestamp            User     Platform  \\\n",
      "0  2023-01-15 12:30:00   User123          Twitter     \n",
      "1  2023-01-15 08:45:00   CommuterX        Twitter     \n",
      "2  2023-01-15 15:45:00   FitnessFan      Instagram    \n",
      "3  2023-01-15 18:20:00   AdventureX       Facebook    \n",
      "4  2023-01-15 19:55:00   ChefCook        Instagram    \n",
      "\n",
      "                                     Hashtags  Retweets  Likes       Country  \\\n",
      "0   #Nature #Park                                  15.0   30.0     USA         \n",
      "1   #Traffic #Morning                               5.0   10.0     Canada      \n",
      "2   #Fitness #Workout                              20.0   40.0   USA           \n",
      "3   #Travel #Adventure                              8.0   15.0     UK          \n",
      "4   #Cooking #Food                                 12.0   25.0    Australia    \n",
      "\n",
      "   Year  Month  Day  Hour  \n",
      "0  2023      1   15    12  \n",
      "1  2023      1   15     8  \n",
      "2  2023      1   15    15  \n",
      "3  2023      1   15    18  \n",
      "4  2023      1   15    19  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"sentimentdataset.csv\")\n",
    "\n",
    "# Get the size and structure\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "print(\"\\nColumn Names:\", df.columns.tolist())\n",
    "\n",
    "# Preview the first 5 rows\n",
    "print(\"\\nFirst 5 records:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f728fe7-bcd1-4c33-ab40-8aeaf0cf4f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before:\n",
      " Unnamed: 0.1    0\n",
      "Unnamed: 0      0\n",
      "Text            0\n",
      "Sentiment       0\n",
      "Timestamp       0\n",
      "User            0\n",
      "Platform        0\n",
      "Hashtags        0\n",
      "Retweets        0\n",
      "Likes           0\n",
      "Country         0\n",
      "Year            0\n",
      "Month           0\n",
      "Day             0\n",
      "Hour            0\n",
      "dtype: int64\n",
      "Missing values after:\n",
      " Unnamed: 0.1    0\n",
      "Unnamed: 0      0\n",
      "Text            0\n",
      "Sentiment       0\n",
      "Timestamp       0\n",
      "User            0\n",
      "Platform        0\n",
      "Hashtags        0\n",
      "Retweets        0\n",
      "Likes           0\n",
      "Country         0\n",
      "Year            0\n",
      "Month           0\n",
      "Day             0\n",
      "Hour            0\n",
      "dtype: int64\n",
      "Removed 0 duplicate rows.\n",
      "Numerical features scaled.\n",
      "   Unnamed: 0.1  Unnamed: 0  \\\n",
      "0     -1.733763   -1.741727   \n",
      "1     -1.729032   -1.737017   \n",
      "2     -1.724301   -1.732306   \n",
      "3     -1.719570   -1.727595   \n",
      "4     -1.714839   -1.722884   \n",
      "\n",
      "                                                Text    Sentiment  \\\n",
      "0   Enjoying a beautiful day at the park!        ...   Positive     \n",
      "1   Traffic was terrible this morning.           ...   Negative     \n",
      "2   Just finished an amazing workout! ðŸ’ª          ...   Positive     \n",
      "3   Excited about the upcoming weekend getaway!  ...   Positive     \n",
      "4   Trying out a new recipe for dinner tonight.  ...   Neutral      \n",
      "\n",
      "             Timestamp            User     Platform  \\\n",
      "0  2023-01-15 12:30:00   User123          Twitter     \n",
      "1  2023-01-15 08:45:00   CommuterX        Twitter     \n",
      "2  2023-01-15 15:45:00   FitnessFan      Instagram    \n",
      "3  2023-01-15 18:20:00   AdventureX       Facebook    \n",
      "4  2023-01-15 19:55:00   ChefCook        Instagram    \n",
      "\n",
      "                                     Hashtags  Retweets     Likes  \\\n",
      "0   #Nature #Park                             -0.922303 -0.916295   \n",
      "1   #Traffic #Morning                         -2.339444 -2.336727   \n",
      "2   #Fitness #Workout                         -0.213733 -0.206079   \n",
      "3   #Travel #Adventure                        -1.914302 -1.981619   \n",
      "4   #Cooking #Food                            -1.347445 -1.271403   \n",
      "\n",
      "        Country      Year     Month       Day      Hour  emotion_encoded  \n",
      "0     USA        0.902984 -1.502582 -0.058718 -0.856774              214  \n",
      "1     Canada     0.902984 -1.502582 -0.058718 -1.829867              195  \n",
      "2   USA          0.902984 -1.502582 -0.058718 -0.126954              214  \n",
      "3     UK         0.902984 -1.502582 -0.058718  0.602866              214  \n",
      "4    Australia   0.902984 -1.502582 -0.058718  0.846139              197  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"sentimentdataset.csv\")\n",
    "\n",
    "# --- Handle Missing Values ---\n",
    "print(\"Missing values before:\\n\", df.isnull().sum())\n",
    "\n",
    "# Drop rows with missing text or label\n",
    "df.dropna(subset=['Text', 'Sentiment'], inplace=True)\n",
    "\n",
    "# Fill missing numerical columns if any\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "print(\"Missing values after:\\n\", df.isnull().sum())\n",
    "\n",
    "# --- Remove Duplicates ---\n",
    "initial_len = len(df)\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f\"Removed {initial_len - len(df)} duplicate rows.\")\n",
    "\n",
    "# --- Outlier Handling (if numerical columns exist) ---\n",
    "# Example: Remove outliers in a column named 'length'\n",
    "if 'length' in df.columns:\n",
    "    q1 = df['length'].quantile(0.25)\n",
    "    q3 = df['length'].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    df = df[(df['length'] >= lower) & (df['length'] <= upper)]\n",
    "    print(\"Outliers removed from 'length' column.\")\n",
    "\n",
    "# --- Label Encoding for Target ---\n",
    "le = LabelEncoder()\n",
    "df['emotion_encoded'] = le.fit_transform(df['Sentiment'])\n",
    "\n",
    "# --- Feature Scaling (if numeric features exist) ---\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Example: scaling if numeric features exist\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "if numeric_cols:\n",
    "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "    print(\"Numerical features scaled.\")\n",
    "\n",
    "# Final structure check\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "174fcd3b-acd2-4eac-b5e3-19ae8b2a0972",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHANGAR\\AppData\\Local\\Temp\\ipykernel_3032\\4231912754.py:45: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(x=\"emotion\", data=df, order=df[\"emotion\"].value_counts().index, palette=\"viridis\")\n",
      "C:\\Users\\SHANGAR\\AppData\\Local\\Temp\\ipykernel_3032\\4231912754.py:49: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "C:\\Users\\SHANGAR\\AppData\\Local\\Temp\\ipykernel_3032\\4231912754.py:53: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x=\"emotion\", y=\"text_length\", data=df, palette=\"Set2\")\n",
      "C:\\Users\\SHANGAR\\AppData\\Local\\Temp\\ipykernel_3032\\4231912754.py:59: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "C:\\Users\\SHANGAR\\AppData\\Local\\Temp\\ipykernel_3032\\4231912754.py:68: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# sentiment_eda_preprocessing.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"sentimentdataset.csv\")  # Make sure this file is in your working directory\n",
    "\n",
    "# Rename columns for consistency\n",
    "df.rename(columns={\"Text\": \"text\", \"Sentiment\": \"emotion\"}, inplace=True)\n",
    "\n",
    "# --- Handle Missing Values ---\n",
    "df.dropna(subset=[\"text\", \"emotion\"], inplace=True)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# --- Remove Duplicates ---\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# --- Add Text Length Feature ---\n",
    "df[\"text_length\"] = df[\"text\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# --- Handle Outliers (Optional for numeric features like text_length) ---\n",
    "q1 = df[\"text_length\"].quantile(0.25)\n",
    "q3 = df[\"text_length\"].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "lower = q1 - 1.5 * iqr\n",
    "upper = q3 + 1.5 * iqr\n",
    "df = df[(df[\"text_length\"] >= lower) & (df[\"text_length\"] <= upper)]\n",
    "\n",
    "# --- Encode Labels ---\n",
    "le = LabelEncoder()\n",
    "df[\"emotion_encoded\"] = le.fit_transform(df[\"emotion\"])\n",
    "\n",
    "# --- Scale Numerical Features ---\n",
    "scaler = StandardScaler()\n",
    "df[[\"text_length_scaled\"]] = scaler.fit_transform(df[[\"text_length\"]])\n",
    "\n",
    "# --- EDA Visuals ---\n",
    "\n",
    "# Emotion Distribution Histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x=\"emotion\", data=df, order=df[\"emotion\"].value_counts().index, palette=\"viridis\")\n",
    "plt.title(\"Distribution of Emotions\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Boxplot of Text Length by Emotion\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=\"emotion\", y=\"text_length\", data=df, palette=\"Set2\")\n",
    "plt.title(\"Text Length by Emotion\")\n",
    "plt.xlabel(\"Emotion\")\n",
    "plt.ylabel(\"Word Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation Heatmap\n",
    "numeric_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "if len(numeric_cols) >= 2:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(df[numeric_cols].corr(), annot=True, cmap=\"coolwarm\")\n",
    "    plt.title(\"Correlation Heatmap\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough numeric columns for a heatmap.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1243359a-cc6b-434b-ab7b-3b2c513dcf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHANGAR\\AppData\\Local\\Temp\\ipykernel_3032\\480926650.py:47: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"sentimentdataset.csv\")\n",
    "df.rename(columns={\"Text\": \"text\", \"Sentiment\": \"emotion\"}, inplace=True)\n",
    "\n",
    "# Drop missing values\n",
    "df.dropna(subset=[\"text\", \"emotion\"], inplace=True)\n",
    "\n",
    "# --- 1. New Feature Creation ---\n",
    "df[\"text_length\"] = df[\"text\"].apply(lambda x: len(str(x).split()))\n",
    "df[\"punctuation_count\"] = df[\"text\"].apply(lambda x: sum([1 for char in str(x) if char in \"!?.\"]))\n",
    "df[\"capital_word_count\"] = df[\"text\"].apply(lambda x: sum([1 for word in str(x).split() if word.isupper()]))\n",
    "\n",
    "# --- 2. Label Encoding ---\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df[\"emotion_encoded\"] = le.fit_transform(df[\"emotion\"])\n",
    "\n",
    "# --- 3. TF-IDF Vectorization ---\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = tfidf.fit_transform(df[\"text\"]).toarray()\n",
    "\n",
    "# Combine with new features\n",
    "X_extra = df[[\"text_length\", \"punctuation_count\", \"capital_word_count\"]].values\n",
    "X_combined = np.hstack((X_tfidf, X_extra))\n",
    "y = df[\"emotion_encoded\"]\n",
    "\n",
    "# --- 4. Feature Scaling ---\n",
    "scaler = StandardScaler()\n",
    "X_combined[:, -3:] = scaler.fit_transform(X_combined[:, -3:])  # Scale extra features\n",
    "\n",
    "\n",
    "\n",
    "# --- 6. Visualization of Impactful New Features ---\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(x=\"emotion\", y=\"text_length\", data=df)\n",
    "plt.title(\"Text Length vs Emotion\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c61eb15c-ad43-4b1d-ab65-2dc03196cf99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# 4. Text vectorization\u001b[39;00m\n\u001b[0;32m     25\u001b[0m tfidf \u001b[38;5;241m=\u001b[39m TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m X \u001b[38;5;241m=\u001b[39m tfidf\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     27\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion_encoded\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# 5. Train/Test split\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2091\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2084\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2085\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2086\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2087\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2088\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2089\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2090\u001b[0m )\n\u001b[1;32m-> 2091\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_transform(raw_documents)\n\u001b[0;32m   2092\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2093\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1372\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1364\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1369\u001b[0m             )\n\u001b[0;32m   1370\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1372\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count_vocab(raw_documents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_vocabulary_)\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1375\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1278\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1276\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[1;32m-> 1278\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1279\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1280\u001b[0m         )\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Load and clean dataset\n",
    "df = pd.read_csv(\"sentimentdataset.csv\")\n",
    "df.rename(columns={\"Text\": \"text\", \"Sentiment\": \"emotion\"}, inplace=True)\n",
    "df.dropna(subset=[\"text\", \"emotion\"], inplace=True)\n",
    "\n",
    "# 2. Filter for selective emotions\n",
    "selected_emotions = [\"joy\", \"sadness\", \"anger\", \"fear\"]\n",
    "df = df[df[\"emotion\"].isin(selected_emotions)]\n",
    "\n",
    "# 3. Encode labels\n",
    "le = LabelEncoder()\n",
    "df[\"emotion_encoded\"] = le.fit_transform(df[\"emotion\"])\n",
    "\n",
    "# 4. Text vectorization\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(df[\"text\"])\n",
    "y = df[\"emotion_encoded\"]\n",
    "\n",
    "# 5. Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. Models to evaluate\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=200),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# 7. Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Classification Report for {name}:\\n\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e2a0e40-5d7d-4f32-a161-f3749f291ce2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 5. Vectorize text using TF-IDF\u001b[39;00m\n\u001b[0;32m     29\u001b[0m tfidf \u001b[38;5;241m=\u001b[39m TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m X \u001b[38;5;241m=\u001b[39m tfidf\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     31\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion_encoded\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# 6. Split into training and testing sets\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2091\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2084\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2085\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2086\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2087\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2088\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2089\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2090\u001b[0m )\n\u001b[1;32m-> 2091\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_transform(raw_documents)\n\u001b[0;32m   2092\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2093\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1372\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1364\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1369\u001b[0m             )\n\u001b[0;32m   1370\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1372\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count_vocab(raw_documents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_vocabulary_)\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1375\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1278\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1276\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[1;32m-> 1278\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1279\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1280\u001b[0m         )\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. Load dataset\n",
    "df = pd.read_csv(\"sentimentdataset.csv\")\n",
    "df.rename(columns={\"Text\": \"text\", \"Sentiment\": \"emotion\"}, inplace=True)\n",
    "\n",
    "# 2. Filter only desired emotions\n",
    "selected_emotions = [\"joy\", \"sadness\", \"anger\", \"fear\"]\n",
    "df = df[df[\"emotion\"].isin(selected_emotions)]\n",
    "\n",
    "# 3. Clean and validate text column\n",
    "df[\"text\"] = df[\"text\"].astype(str).str.strip()\n",
    "df = df[df[\"text\"].str.len() > 0]  # Remove empty strings\n",
    "df = df[~df[\"text\"].isin(ENGLISH_STOP_WORDS)]  # Optional: remove entries that are only stopwords\n",
    "\n",
    "# 4. Encode target labels\n",
    "le = LabelEncoder()\n",
    "df[\"emotion_encoded\"] = le.fit_transform(df[\"emotion\"])\n",
    "\n",
    "# 5. Vectorize text using TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(df[\"text\"])\n",
    "y = df[\"emotion_encoded\"]\n",
    "\n",
    "# 6. Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 7. Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=200),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# 8. Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\nClassification Report for {name}:\\n\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f2d1476-c811-41f1-be06-02bbda761af6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'emotion'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'emotion'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 36\u001b[0m\n\u001b[0;32m     29\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogistic Regression\u001b[39m\u001b[38;5;124m\"\u001b[39m: LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m),\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaive Bayes\u001b[39m\u001b[38;5;124m\"\u001b[39m: MultinomialNB(),\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m\"\u001b[39m: RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     33\u001b[0m }\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# 8. Train and evaluate each model\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m target_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munique())  \u001b[38;5;66;03m# Get unique emotion names in consistent order\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Training: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'emotion'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. Load dataset\n",
    "df = pd.read_csv(\"sentimentdataset.csv\")\n",
    "df.rename(columns={\"Text\": \"text\", \"Sentiment\": \"emotion\"}, inplace=True)\n",
    "\n",
    "# 2. Filter only desired emotions\n",
    "selected_emotions = [\"joy\", \"sadness\", \"anger\", \"fear\"]\n",
    "df = df[df[\"emotion\"].isin(selected_emotions)]\n",
    "\n",
    "# 3. Clean and validate text column\n",
    "df[\"text\"] = df[\"text\"].astype(str).str.strip()\n",
    "df = df[df[\"text\"].apply(lambda x: len(x.split()) > 1)]  # Remove rows with <= 1 word\n",
    "\n",
    "\n",
    "\n",
    "# 6. Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 7. Define models to test\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=200),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# 8. Train and evaluate each model\n",
    "target_names = sorted(df[\"emotion\"].unique())  # Get unique emotion names in consistent order\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Classification Report for {name}:\\n\")\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "141b5a23-5123-4282-bf51-0104204fb87d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'emotion'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'emotion'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Encode emotion labels\u001b[39;00m\n\u001b[0;32m     24\u001b[0m le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m---> 25\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion_encoded\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Vectorize text using TF-IDF\u001b[39;00m\n\u001b[0;32m     28\u001b[0m tfidf \u001b[38;5;241m=\u001b[39m TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m, stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'emotion'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"sentimentdataset.csv\")\n",
    "df.rename(columns={\"Text\": \"text\", \"Sentiment\": \"emotion\"}, inplace=True)\n",
    "\n",
    "# Filter for selective emotions\n",
    "selected_emotions = [\"joy\", \"sadness\", \"anger\", \"fear\"]\n",
    "df = df[df[\"emotion\"].isin(selected_emotions)]\n",
    "\n",
    "# Clean and validate text column\n",
    "df[\"text\"] = df[\"text\"].astype(str).str.strip()\n",
    "df = df[df[\"text\"].apply(lambda x: len(x.split()) > 1)]  # Keep only texts with more than one word\n",
    "\n",
    "# Encode emotion labels\n",
    "le = LabelEncoder()\n",
    "df[\"emotion_encoded\"] = le.fit_transform(df[\"emotion\"])\n",
    "\n",
    "# Vectorize text using TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words=None)\n",
    "X = tfidf.fit_transform(df[\"text\"])\n",
    "y = df[\"emotion_encoded\"]\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=200),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Get class names\n",
    "target_names = le.classes_\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\nClassification Report for {name}:\\n\")\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f30f6db-25e7-4ac8-aeda-0bfb47dd35d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LabelEncoder' object has no attribute 'classes_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 45\u001b[0m\n\u001b[0;32m     35\u001b[0m results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m: name,\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: acc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m: rmse\n\u001b[0;32m     42\u001b[0m })\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred, target_names\u001b[38;5;241m=\u001b[39mle\u001b[38;5;241m.\u001b[39mclasses_))\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Confusion Matrix\u001b[39;00m\n\u001b[0;32m     48\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_pred)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LabelEncoder' object has no attribute 'classes_'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    mean_squared_error\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Assume df, X_train, X_test, y_train, y_test, models are already defined\n",
    "# And label encoder was already applied -> le\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    prec = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "    rec = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1-Score\": f1,\n",
    "        \"RMSE\": rmse\n",
    "    })\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title(f\"Confusion Matrix - {name}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve (for models that support predict_proba)\n",
    "    if y_proba is not None and len(le.classes_) == 2:\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba[:, 1])\n",
    "        auc = roc_auc_score(y_test, y_proba[:, 1])\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label=f\"{name} (AUC = {auc:.2f})\")\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "        plt.title(\"ROC Curve\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Model Comparison Table\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n=== Model Comparison Table ===\")\n",
    "print(results_df.sort_values(by=\"F1-Score\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1c220fd-3e5e-4260-ab5f-34a0cc6613b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SHANGAR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0.1  Unnamed: 0  \\\n",
      "0             0           0   \n",
      "1             1           1   \n",
      "2             2           2   \n",
      "3             3           3   \n",
      "4             4           4   \n",
      "\n",
      "                                                Text    Sentiment  \\\n",
      "0   Enjoying a beautiful day at the park!        ...   Positive     \n",
      "1   Traffic was terrible this morning.           ...   Negative     \n",
      "2   Just finished an amazing workout! ðŸ’ª          ...   Positive     \n",
      "3   Excited about the upcoming weekend getaway!  ...   Positive     \n",
      "4   Trying out a new recipe for dinner tonight.  ...   Neutral      \n",
      "\n",
      "             Timestamp            User     Platform  \\\n",
      "0  2023-01-15 12:30:00   User123          Twitter     \n",
      "1  2023-01-15 08:45:00   CommuterX        Twitter     \n",
      "2  2023-01-15 15:45:00   FitnessFan      Instagram    \n",
      "3  2023-01-15 18:20:00   AdventureX       Facebook    \n",
      "4  2023-01-15 19:55:00   ChefCook        Instagram    \n",
      "\n",
      "                                     Hashtags  Retweets  Likes       Country  \\\n",
      "0   #Nature #Park                                  15.0   30.0     USA         \n",
      "1   #Traffic #Morning                               5.0   10.0     Canada      \n",
      "2   #Fitness #Workout                              20.0   40.0   USA           \n",
      "3   #Travel #Adventure                              8.0   15.0     UK          \n",
      "4   #Cooking #Food                                 12.0   25.0    Australia    \n",
      "\n",
      "   Year  Month  Day  Hour  \n",
      "0  2023      1   15    12  \n",
      "1  2023      1   15     8  \n",
      "2  2023      1   15    15  \n",
      "3  2023      1   15    18  \n",
      "4  2023      1   15    19  \n",
      "Accuracy: 0.11564625850340136\n",
      "\n",
      "Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "         Acceptance          0.00      0.00      0.00         2\n",
      "           Admiration        0.00      0.00      0.00         1\n",
      "        Admiration           0.00      0.00      0.00         1\n",
      "         Affection           0.00      0.00      0.00         1\n",
      "      Ambivalence            0.00      0.00      0.00         1\n",
      "         Anger               0.00      0.00      0.00         1\n",
      "        Anticipation         0.00      0.00      0.00         1\n",
      "        Arousal              0.00      0.00      0.00         3\n",
      "                  Awe        0.00      0.00      0.00         1\n",
      "         Awe                 0.00      0.00      0.00         1\n",
      "                  Bad        0.00      0.00      0.00         1\n",
      "             Betrayal        0.00      0.00      0.00         2\n",
      "        Betrayal             0.00      0.00      0.00         1\n",
      "         Bitter              0.00      0.00      0.00         1\n",
      "           Bitterness        0.00      0.00      0.00         1\n",
      "          Bittersweet        0.00      0.00      0.00         1\n",
      "              Boredom        0.00      0.00      0.00         1\n",
      "         Calmness            0.00      0.00      0.00         1\n",
      "          Captivation        0.00      0.00      0.00         1\n",
      "     Celestial Wonder        0.00      0.00      0.00         1\n",
      "             Colorful        0.00      0.00      0.00         1\n",
      "      Confusion              0.00      0.00      0.00         3\n",
      "           Connection        0.00      0.00      0.00         1\n",
      "        Contemplation        0.00      0.00      0.00         1\n",
      "          Contentment        0.00      0.00      0.00         3\n",
      "        Contentment          0.00      0.00      0.00         1\n",
      "         Coziness            0.00      0.00      0.00         1\n",
      "         Creativity          0.00      0.00      0.00         1\n",
      "            Curiosity        0.00      0.00      0.00         2\n",
      "          Curiosity          0.00      0.00      0.00         1\n",
      "      Curiosity              0.00      0.00      0.00         2\n",
      "           Desolation        0.00      0.00      0.00         1\n",
      "           Devastated        0.00      0.00      0.00         2\n",
      "              Disgust        0.00      0.00      0.00         1\n",
      "         Disgust             0.00      0.00      0.00         2\n",
      "        Elation              0.00      0.00      0.00         3\n",
      "             Elegance        0.00      0.00      0.00         1\n",
      "          Embarrassed        0.00      0.00      0.00         1\n",
      "       EmotionalStorm        0.00      0.00      0.00         1\n",
      "        Empowerment          0.00      0.00      0.00         1\n",
      "         Enjoyment           0.00      0.00      0.00         2\n",
      "           Enthusiasm        0.00      0.00      0.00         1\n",
      "              Envious        0.00      0.00      0.00         2\n",
      "  Envisioning History        0.00      0.00      0.00         1\n",
      "         Euphoria            0.00      0.00      0.00         1\n",
      "           Excitement        0.09      0.33      0.14         3\n",
      "         Excitement          0.00      0.00      0.00         3\n",
      "        Excitement           0.00      0.00      0.00         1\n",
      "         Fear                0.00      0.00      0.00         1\n",
      "              Fearful        0.00      0.00      0.00         1\n",
      "           Frustrated        0.00      0.00      0.00         1\n",
      "          Frustration        0.00      0.00      0.00         3\n",
      "         Fulfillment         0.00      0.00      0.00         2\n",
      "             Grateful        0.00      0.00      0.00         1\n",
      "      Grief                  0.00      0.00      0.00         1\n",
      "                Happy        0.00      0.00      0.00         6\n",
      "                 Hate        0.00      0.00      0.00         2\n",
      "           Heartbreak        0.00      0.00      0.00         2\n",
      "              Hopeful        1.00      1.00      1.00         1\n",
      "        InnerJourney         0.00      0.00      0.00         1\n",
      "        Inspiration          0.00      0.00      0.00         1\n",
      "             Inspired        0.00      0.00      0.00         1\n",
      "            Isolation        0.00      0.00      0.00         1\n",
      "          Jealousy           0.00      0.00      0.00         1\n",
      "                  Joy        0.13      0.75      0.22         8\n",
      "         Joy                 0.00      0.00      0.00         1\n",
      "        JoyfulReunion        0.00      0.00      0.00         1\n",
      "         Kind                0.00      0.00      0.00         1\n",
      "           Loneliness        0.00      0.00      0.00         1\n",
      "      Loneliness             0.00      0.00      0.00         1\n",
      "             LostLove        0.00      0.00      0.00         1\n",
      "      Melancholy             0.00      0.00      0.00         2\n",
      "       Miscalculation        0.00      0.00      0.00         1\n",
      "              Neutral        0.00      0.00      0.00         1\n",
      "        Nostalgia            0.00      0.00      0.00         1\n",
      "      Nostalgia              0.00      0.00      0.00         1\n",
      "      Numbness               0.00      0.00      0.00         1\n",
      "          Overwhelmed        0.00      0.00      0.00         1\n",
      "              Playful        0.00      0.00      0.00         2\n",
      "            Positive         0.10      1.00      0.18         9\n",
      "                Proud        0.00      0.00      0.00         1\n",
      "        Reflection           0.00      0.00      0.00         1\n",
      "       Regret                0.00      0.00      0.00         1\n",
      "           Resilience        0.00      0.00      0.00         1\n",
      "            Reverence        0.00      0.00      0.00         1\n",
      "         Sadness             0.00      0.00      0.00         2\n",
      "        Satisfaction         0.00      0.00      0.00         1\n",
      "             Serenity        0.00      0.00      0.00         2\n",
      "      Serenity               0.00      0.00      0.00         2\n",
      "             Solitude        0.00      0.00      0.00         1\n",
      "          Sorrow             0.00      0.00      0.00         1\n",
      "         Spark               0.00      0.00      0.00         1\n",
      "         Surprise            0.00      0.00      0.00         1\n",
      "        Thrill               0.00      0.00      0.00         1\n",
      "             Vibrancy        0.00      0.00      0.00         1\n",
      " Whispers of the Past        0.00      0.00      0.00         1\n",
      "                 Zest        0.00      0.00      0.00         1\n",
      "\n",
      "              accuracy                           0.12       147\n",
      "             macro avg       0.01      0.03      0.02       147\n",
      "          weighted avg       0.02      0.12      0.03       147\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"sentimentdataset.csv\")\n",
    "\n",
    "# Preview the data\n",
    "print(df.head())\n",
    "\n",
    "# Assuming the columns are 'text' and 'sentiment'. Adjust if needed.\n",
    "text_column = 'Text'       # change to the correct column name\n",
    "label_column = 'Sentiment' # change to the correct column name\n",
    "\n",
    "# Clean text data\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)  # Remove URLs\n",
    "    text = re.sub(r'\\@w+|\\#','', text)  # Remove mentions and hashtags\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)  # Remove punctuation/numbers\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    ps = PorterStemmer()\n",
    "    tokens = [ps.stem(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df[text_column] = df[text_column].astype(str).apply(preprocess)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[text_column], df[label_column], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Model training\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Prediction and evaluation\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c392d19-c90d-4033-9222-1f77bc46905f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SHANGAR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ' Curiosity '",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 68\u001b[0m\n\u001b[0;32m     66\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[0;32m     67\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m rmse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 Score (Weighted): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:502\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    492\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    493\u001b[0m         (\n\u001b[0;32m    494\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquared\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated in version 1.4 and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[1;32m--> 502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[0;32m    503\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[0;32m    504\u001b[0m         )\n\u001b[0;32m    506\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    507\u001b[0m     y_true, y_pred, multioutput\n\u001b[0;32m    508\u001b[0m )\n\u001b[0;32m    509\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:581\u001b[0m, in \u001b[0;36mroot_mean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    523\u001b[0m     {\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    532\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m ):\n\u001b[0;32m    534\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Root mean squared error regression loss.\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \n\u001b[0;32m    536\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;124;03m    0.822...\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    580\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\n\u001b[1;32m--> 581\u001b[0m         mean_squared_error(\n\u001b[0;32m    582\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    583\u001b[0m         )\n\u001b[0;32m    584\u001b[0m     )\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(multioutput, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    587\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m multioutput \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:506\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[0;32m    502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[0;32m    503\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[0;32m    504\u001b[0m         )\n\u001b[1;32m--> 506\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    507\u001b[0m     y_true, y_pred, multioutput\n\u001b[0;32m    508\u001b[0m )\n\u001b[0;32m    509\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    510\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:112\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[0;32m    109\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, multioutput, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m    111\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m--> 112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1012\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1012\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1015\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1016\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:751\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    749\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 751\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    753\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1031\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[0;32m    983\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1030\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1031\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   1033\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ' Curiosity '"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    mean_squared_error,\n",
    "    classification_report,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"sentimentdataset.csv\")\n",
    "\n",
    "# Adjust column names as needed\n",
    "text_column = 'Text'       # Replace with actual column name\n",
    "label_column = 'Sentiment' # Replace with actual column name\n",
    "\n",
    "# Preprocess text\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    ps = PorterStemmer()\n",
    "    tokens = [ps.stem(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df[text_column] = df[text_column].astype(str).apply(preprocess)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[text_column], df[label_column], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Vectorize text\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Train model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test_vec)\n",
    "y_proba = model.predict_proba(X_test_vec)\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score (Weighted): {f1:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve (only for binary classification)\n",
    "if len(model.classes_) == 2:\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba[:, 1], pos_label=model.classes_[1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"ROC Curve is not supported for multi-class without binarization.\")\n",
    "\n",
    "# Error Analysis\n",
    "errors = pd.DataFrame({\n",
    "    'Text': X_test,\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred\n",
    "})\n",
    "errors = errors[errors['Actual'] != errors['Predicted']]\n",
    "print(\"Sample Misclassifications:\\n\", errors.head())\n",
    "\n",
    "# Optional: Model comparison placeholder\n",
    "# You can extend this if you train more models\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Naive Bayes'],\n",
    "    'Accuracy': [accuracy],\n",
    "    'F1 Score': [f1],\n",
    "    'RMSE': [rmse]\n",
    "})\n",
    "print(\"\\nModel Comparison:\\n\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1eb6b4b3-7bd9-4e1c-9009-a228142c3985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ' Curiosity '",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[0;32m      4\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 'weighted' handles class imbalance\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m rmse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 Score (Weighted): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:502\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    492\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    493\u001b[0m         (\n\u001b[0;32m    494\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquared\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated in version 1.4 and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[1;32m--> 502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[0;32m    503\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[0;32m    504\u001b[0m         )\n\u001b[0;32m    506\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    507\u001b[0m     y_true, y_pred, multioutput\n\u001b[0;32m    508\u001b[0m )\n\u001b[0;32m    509\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:581\u001b[0m, in \u001b[0;36mroot_mean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    523\u001b[0m     {\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    532\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m ):\n\u001b[0;32m    534\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Root mean squared error regression loss.\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \n\u001b[0;32m    536\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;124;03m    0.822...\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    580\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\n\u001b[1;32m--> 581\u001b[0m         mean_squared_error(\n\u001b[0;32m    582\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    583\u001b[0m         )\n\u001b[0;32m    584\u001b[0m     )\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(multioutput, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    587\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m multioutput \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:506\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[0;32m    502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[0;32m    503\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[0;32m    504\u001b[0m         )\n\u001b[1;32m--> 506\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    507\u001b[0m     y_true, y_pred, multioutput\n\u001b[0;32m    508\u001b[0m )\n\u001b[0;32m    509\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    510\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:112\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[0;32m    109\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, multioutput, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m    111\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m--> 112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1012\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1012\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1015\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1016\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:751\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    749\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 751\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    753\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1031\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[0;32m    983\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1030\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1031\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   1033\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ' Curiosity '"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, mean_squared_error, roc_curve, auc\n",
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # 'weighted' handles class imbalance\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score (Weighted): {f1:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "736297be-ff2b-41c3-b1c9-fcedbb280d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1088\n",
      "F1 Score (Weighted): 0.0312\n",
      "\n",
      "Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "         Acceptance          0.00      0.00      0.00         2\n",
      "           Admiration        0.00      0.00      0.00         1\n",
      "        Admiration           0.00      0.00      0.00         1\n",
      "         Affection           0.00      0.00      0.00         1\n",
      "      Ambivalence            0.00      0.00      0.00         1\n",
      "         Anger               0.00      0.00      0.00         1\n",
      "        Anticipation         0.00      0.00      0.00         1\n",
      "        Arousal              0.00      0.00      0.00         3\n",
      "                  Awe        0.00      0.00      0.00         1\n",
      "         Awe                 0.00      0.00      0.00         1\n",
      "                  Bad        0.00      0.00      0.00         1\n",
      "             Betrayal        0.00      0.00      0.00         2\n",
      "        Betrayal             0.00      0.00      0.00         1\n",
      "         Bitter              0.00      0.00      0.00         1\n",
      "           Bitterness        0.00      0.00      0.00         1\n",
      "          Bittersweet        0.00      0.00      0.00         1\n",
      "              Boredom        0.00      0.00      0.00         1\n",
      "         Calmness            0.00      0.00      0.00         1\n",
      "          Captivation        0.00      0.00      0.00         1\n",
      "     Celestial Wonder        0.00      0.00      0.00         1\n",
      "             Colorful        0.00      0.00      0.00         1\n",
      "      Confusion              0.00      0.00      0.00         3\n",
      "           Connection        0.00      0.00      0.00         1\n",
      "        Contemplation        0.00      0.00      0.00         1\n",
      "          Contentment        0.00      0.00      0.00         3\n",
      "        Contentment          0.00      0.00      0.00         1\n",
      "         Coziness            0.00      0.00      0.00         1\n",
      "         Creativity          0.00      0.00      0.00         1\n",
      "            Curiosity        0.00      0.00      0.00         2\n",
      "          Curiosity          0.00      0.00      0.00         1\n",
      "      Curiosity              0.00      0.00      0.00         2\n",
      "           Desolation        0.00      0.00      0.00         1\n",
      "           Devastated        0.00      0.00      0.00         2\n",
      "              Disgust        0.00      0.00      0.00         1\n",
      "         Disgust             0.00      0.00      0.00         2\n",
      "        Elation              0.00      0.00      0.00         3\n",
      "             Elegance        0.00      0.00      0.00         1\n",
      "          Embarrassed        0.00      0.00      0.00         1\n",
      "       EmotionalStorm        0.00      0.00      0.00         1\n",
      "        Empowerment          0.00      0.00      0.00         1\n",
      "         Enjoyment           0.00      0.00      0.00         2\n",
      "           Enthusiasm        0.00      0.00      0.00         1\n",
      "              Envious        0.00      0.00      0.00         2\n",
      "  Envisioning History        0.00      0.00      0.00         1\n",
      "         Euphoria            0.00      0.00      0.00         1\n",
      "           Excitement        0.08      0.33      0.12         3\n",
      "         Excitement          0.00      0.00      0.00         3\n",
      "        Excitement           0.00      0.00      0.00         1\n",
      "         Fear                0.00      0.00      0.00         1\n",
      "              Fearful        0.00      0.00      0.00         1\n",
      "           Frustrated        0.00      0.00      0.00         1\n",
      "          Frustration        0.00      0.00      0.00         3\n",
      "         Fulfillment         0.00      0.00      0.00         2\n",
      "             Grateful        0.00      0.00      0.00         1\n",
      "      Grief                  0.00      0.00      0.00         1\n",
      "                Happy        0.00      0.00      0.00         6\n",
      "                 Hate        0.00      0.00      0.00         2\n",
      "           Heartbreak        0.00      0.00      0.00         2\n",
      "              Hopeful        1.00      1.00      1.00         1\n",
      "        InnerJourney         0.00      0.00      0.00         1\n",
      "        Inspiration          0.00      0.00      0.00         1\n",
      "             Inspired        0.00      0.00      0.00         1\n",
      "            Isolation        0.00      0.00      0.00         1\n",
      "          Jealousy           0.00      0.00      0.00         1\n",
      "                  Joy        0.12      0.75      0.20         8\n",
      "         Joy                 0.00      0.00      0.00         1\n",
      "        JoyfulReunion        0.00      0.00      0.00         1\n",
      "         Kind                0.00      0.00      0.00         1\n",
      "           Loneliness        0.00      0.00      0.00         1\n",
      "      Loneliness             0.00      0.00      0.00         1\n",
      "             LostLove        0.00      0.00      0.00         1\n",
      "      Melancholy             0.00      0.00      0.00         2\n",
      "       Miscalculation        0.00      0.00      0.00         1\n",
      "              Neutral        0.00      0.00      0.00         1\n",
      "        Nostalgia            0.00      0.00      0.00         1\n",
      "      Nostalgia              0.00      0.00      0.00         1\n",
      "      Numbness               0.00      0.00      0.00         1\n",
      "          Overwhelmed        0.00      0.00      0.00         1\n",
      "              Playful        0.00      0.00      0.00         2\n",
      "            Positive         0.10      0.89      0.18         9\n",
      "                Proud        0.00      0.00      0.00         1\n",
      "        Reflection           0.00      0.00      0.00         1\n",
      "       Regret                0.00      0.00      0.00         1\n",
      "           Resilience        0.00      0.00      0.00         1\n",
      "            Reverence        0.00      0.00      0.00         1\n",
      "         Sadness             0.00      0.00      0.00         2\n",
      "        Satisfaction         0.00      0.00      0.00         1\n",
      "             Serenity        0.00      0.00      0.00         2\n",
      "      Serenity               0.00      0.00      0.00         2\n",
      "             Solitude        0.00      0.00      0.00         1\n",
      "          Sorrow             0.00      0.00      0.00         1\n",
      "         Spark               0.00      0.00      0.00         1\n",
      "         Surprise            0.00      0.00      0.00         1\n",
      "        Thrill               0.00      0.00      0.00         1\n",
      "             Vibrancy        0.00      0.00      0.00         1\n",
      " Whispers of the Past        0.00      0.00      0.00         1\n",
      "                 Zest        0.00      0.00      0.00         1\n",
      "\n",
      "              accuracy                           0.11       147\n",
      "             macro avg       0.01      0.03      0.02       147\n",
      "          weighted avg       0.02      0.11      0.03       147\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Curve skipped: multi-class ROC not visualized here.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHANGAR\\AppData\\Local\\Temp\\ipykernel_3032\\429692536.py:24: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    classification_report, accuracy_score, f1_score, confusion_matrix, roc_auc_score)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # 'weighted' handles imbalance\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score (Weighted): {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=model.classes_, yticklabels=model.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "# ROC Curve (if binary or one-vs-rest)\n",
    "if len(model.classes_) == 2:\n",
    "    y_test_bin = label_binarize(y_test, classes=model.classes_)\n",
    "    y_pred_proba = model.predict_proba(X_test_vec)[:, 1]\n",
    "    auc = roc_auc_score(y_test_bin, y_pred_proba)\n",
    "    print(f\"ROC AUC Score: {auc:.4f}\")\n",
    "else:\n",
    "    print(\"ROC Curve skipped: multi-class ROC not visualized here.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c9262e7-2e90-4542-b12b-3f09ba716e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\Users\\SHANGAR\\AppData\\Local\\Temp\\ipykernel_3032\\4007006949.py:41: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Binarize the labels\n",
    "classes = model.classes_  # or: np.unique(y)\n",
    "y_test_bin = label_binarize(y_test, classes=classes)\n",
    "n_classes = y_test_bin.shape[1]\n",
    "\n",
    "# Predict probabilities for each class\n",
    "y_score = model.predict_proba(X_test_vec)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"Class {classes[i]} (AUC = {roc_auc[i]:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Random Guess\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Multi-Class ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb344f7a-eea9-4eaf-81d4-d8c64f840d9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'emotion'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'emotion'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# 4. Encode emotion labels\u001b[39;00m\n\u001b[0;32m     25\u001b[0m le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m---> 26\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion_encoded\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 5. TF-IDF Vectorization\u001b[39;00m\n\u001b[0;32m     29\u001b[0m tfidf \u001b[38;5;241m=\u001b[39m TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'emotion'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 1. Load dataset\n",
    "df = pd.read_csv(\"sentimentdataset.csv\")\n",
    "df.rename(columns={\"Text\": \"text\", \"Sentiment\": \"emotion\"}, inplace=True)\n",
    "\n",
    "# 2. Select specific emotions\n",
    "selected_emotions = [\"joy\", \"sadness\", \"anger\", \"fear\"]\n",
    "df = df[df[\"emotion\"].isin(selected_emotions)]\n",
    "\n",
    "# 3. Clean text column\n",
    "df[\"text\"] = df[\"text\"].astype(str).str.strip()\n",
    "df = df[df[\"text\"].apply(lambda x: len(x.split()) > 1)]\n",
    "\n",
    "# 4. Encode emotion labels\n",
    "le = LabelEncoder()\n",
    "df[\"emotion_encoded\"] = le.fit_transform(df[\"emotion\"])\n",
    "\n",
    "# 5. TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(df[\"text\"])\n",
    "y = df[\"emotion_encoded\"]\n",
    "\n",
    "# 6. Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 7. Define models with reasons\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=200),  # ðŸ”¹ Baseline model: fast, interpretable\n",
    "    \"Naive Bayes\": MultinomialNB(),                           # ðŸ”¹ Probabilistic, good for text frequency\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),# ðŸ”¹ Handles non-linear patterns well\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),        # ðŸ”¹ Advanced ensemble, often very accurate\n",
    "    \"Support Vector Machine\": SVC(kernel='linear')            # ðŸ”¹ Great for high-dimensional TF-IDF text\n",
    "}\n",
    "\n",
    "# 8. Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
